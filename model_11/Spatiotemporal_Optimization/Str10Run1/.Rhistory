withheld_df$spp[irow],
withheld_df$year[irow]]
}
#Calculate the mean observed density for the calculation of the RRMSE
#There are many ways to do this and I chose for the normalizing constant to
#be specific to year and species.
mean_pred_density = aggregate(obs_density ~ spp + year, data = withheld_df,
FUN = mean)
#Calculate RRMSE for each year for each species using the mean observed
#density calculated above
for (ispp in 1:15) {
for (itime in 1:11) {
split_df <- subset(withheld_df,
spp == ispp & year == years[itime])
temp_RMSE <- sqrt(mean((split_df$obs_density - split_df$pred_density)^2))
temp_mean_pred_density <-
mean_pred_density[mean_pred_density$spp == ispp
& mean_pred_density$year == years[itime],
'obs_density']
RRMSE[ifold, ispp, itime] = temp_RMSE / temp_mean_pred_density
}
}
print(paste0('Done with fold ', ifold))
}
CV_df$pred_jnll
#Average RRMSE across years
round(apply(RRMSE, MARGIN = c(1:2), mean), 2)
CV_df$pred_jnll
#Average RRMSE across years
round(apply(RRMSE, MARGIN = c(1:2), mean), 2)
###############################################################################
## Project:       Relative Root Mean Square Error Calculations
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Calculate RRMSE for each 5-fold CrossValidation Run
###############################################################################
rm(list = ls())
##################################################
####   Import Required packages
##################################################
library(VAST)
library(RANN)
##################################################
####   Set up directories
##################################################
VAST_dir = "C:/Users/zack.oyafuso/Desktop/VAST_Runs/VAST_output10b/"
##################################################
####   Result Objects
##################################################
CV_df = data.frame(ifold = 1:5)
RRMSE = array(dim = c(5, ncol = 15, 11))
for (ifold in 1:5){
##################################################
####   Load Result Object
##################################################
load(paste0(VAST_dir, "CV_", ifold, '/fit.RData'))
##################################################
####   Some Convergence/Hessian Checks
##################################################
#Final maximum absolute gradient
CV_df$max_grad[ifold] <-
max(abs(fit_new$parameter_estimates$diagnostics$final_gradient))
#Is hessian is positive definite?
CV_df$pdHess[ifold] <- fit_new$parameter_estimates$SD$pdHess
#check_fit chekcs bounds, TRUE is bad and FALSE is good
CV_df$bound_check[ifold] <- check_fit(fit_new$parameter_estimates)
CV_df$pred_jnll[ifold] <- fit_new$Report$pred_jnll
##################################################
####   Calculate RRMSE
##################################################
withheld_idx <- which(fit_new$data_list$PredTF_i == T)
#Withheld data locations
withheld_df <- data.frame(
idx =  withheld_idx,
E_km = fit_new$spatial_list$loc_i[withheld_idx,'E_km'],
N_km = fit_new$spatial_list$loc_i[withheld_idx,'N_km'],
spp = 1+fit_new$data_frame$c_iz[withheld_idx],
year = 1+fit_new$data_list$t_iz[withheld_idx,1],
obs_density = (fit_new$data_frame$b_i/fit_new$data_frame$a_i)[withheld_idx]
)
#Grid locations
loc_g <- fit_new$spatial_list$loc_g
#Year indices
years = unique(withheld_df$year)
#which grids are closest to each withheld data location
grid_idx <- RANN::nn2(query = withheld_df[,c('E_km', 'N_km')],
data = loc_g,
k = 1)$nn.idx
#For each station, locate cell/spp/year density predictions that correspond
#to the location of the data
for (irow in 1:nrow(withheld_df)) {
withheld_df$pred_density[irow] <-
fit_new$Report$D_gcy[grid_idx[irow],
withheld_df$spp[irow],
withheld_df$year[irow]]
}
#Calculate the mean observed density for the calculation of the RRMSE
#There are many ways to do this and I chose for the normalizing constant to
#be specific to year and species.
mean_pred_density = aggregate(obs_density ~ spp + year, data = withheld_df,
FUN = mean)
#Calculate RRMSE for each year for each species using the mean observed
#density calculated above
for (ispp in 1:15) {
for (itime in 1:11) {
split_df <- subset(withheld_df,
spp == ispp & year == years[itime])
temp_RMSE <- sqrt(mean((split_df$obs_density - split_df$pred_density)^2))
temp_mean_pred_density <-
mean_pred_density[mean_pred_density$spp == ispp
& mean_pred_density$year == years[itime],
'obs_density']
RRMSE[ifold, ispp, itime] = temp_RMSE / temp_mean_pred_density
}
}
print(paste0('Done with fold ', ifold))
}
CV_df$pred_jnll
#Average RRMSE across years
round(apply(RRMSE, MARGIN = c(1:2), mean), 2)
###############################################################################
## Project:       Relative Root Mean Square Error Calculations
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Calculate RRMSE for each 5-fold CrossValidation Run
###############################################################################
rm(list = ls())
##################################################
####   Import Required packages
##################################################
library(VAST)
library(RANN)
##################################################
####   Set up directories
##################################################
VAST_dir = "C:/Users/zack.oyafuso/Desktop/VAST_Runs/VAST_output10c/"
##################################################
####   Result Objects
##################################################
CV_df = data.frame(ifold = 1:5)
RRMSE = array(dim = c(5, ncol = 15, 11))
for (ifold in 1:5){
##################################################
####   Load Result Object
##################################################
load(paste0(VAST_dir, "CV_", ifold, '/fit.RData'))
##################################################
####   Some Convergence/Hessian Checks
##################################################
#Final maximum absolute gradient
CV_df$max_grad[ifold] <-
max(abs(fit_new$parameter_estimates$diagnostics$final_gradient))
#Is hessian is positive definite?
CV_df$pdHess[ifold] <- fit_new$parameter_estimates$SD$pdHess
#check_fit chekcs bounds, TRUE is bad and FALSE is good
CV_df$bound_check[ifold] <- check_fit(fit_new$parameter_estimates)
CV_df$pred_jnll[ifold] <- fit_new$Report$pred_jnll
##################################################
####   Calculate RRMSE
##################################################
withheld_idx <- which(fit_new$data_list$PredTF_i == T)
#Withheld data locations
withheld_df <- data.frame(
idx =  withheld_idx,
E_km = fit_new$spatial_list$loc_i[withheld_idx,'E_km'],
N_km = fit_new$spatial_list$loc_i[withheld_idx,'N_km'],
spp = 1+fit_new$data_frame$c_iz[withheld_idx],
year = 1+fit_new$data_list$t_iz[withheld_idx,1],
obs_density = (fit_new$data_frame$b_i/fit_new$data_frame$a_i)[withheld_idx]
)
#Grid locations
loc_g <- fit_new$spatial_list$loc_g
#Year indices
years = unique(withheld_df$year)
#which grids are closest to each withheld data location
grid_idx <- RANN::nn2(query = withheld_df[,c('E_km', 'N_km')],
data = loc_g,
k = 1)$nn.idx
#For each station, locate cell/spp/year density predictions that correspond
#to the location of the data
for (irow in 1:nrow(withheld_df)) {
withheld_df$pred_density[irow] <-
fit_new$Report$D_gcy[grid_idx[irow],
withheld_df$spp[irow],
withheld_df$year[irow]]
}
#Calculate the mean observed density for the calculation of the RRMSE
#There are many ways to do this and I chose for the normalizing constant to
#be specific to year and species.
mean_pred_density = aggregate(obs_density ~ spp + year, data = withheld_df,
FUN = mean)
#Calculate RRMSE for each year for each species using the mean observed
#density calculated above
for (ispp in 1:15) {
for (itime in 1:11) {
split_df <- subset(withheld_df,
spp == ispp & year == years[itime])
temp_RMSE <- sqrt(mean((split_df$obs_density - split_df$pred_density)^2))
temp_mean_pred_density <-
mean_pred_density[mean_pred_density$spp == ispp
& mean_pred_density$year == years[itime],
'obs_density']
RRMSE[ifold, ispp, itime] = temp_RMSE / temp_mean_pred_density
}
}
print(paste0('Done with fold ', ifold))
}
CV_df$pred_jnll
#Average RRMSE across years
round(apply(RRMSE, MARGIN = c(1:2), mean), 2)
###############################################################################
## Project:       Relative Root Mean Square Error Calculations
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Calculate RRMSE for each 5-fold CrossValidation Run
###############################################################################
rm(list = ls())
##################################################
####   Import Required packages
##################################################
library(VAST)
library(RANN)
##################################################
####   Set up directories
##################################################
VAST_dir = "C:/Users/zack.oyafuso/Desktop/VAST_Runs/VAST_output10d/"
##################################################
####   Result Objects
##################################################
CV_df = data.frame(ifold = 1:5)
RRMSE = array(dim = c(5, ncol = 15, 11))
for (ifold in 1:5){
##################################################
####   Load Result Object
##################################################
load(paste0(VAST_dir, "CV_", ifold, '/fit.RData'))
##################################################
####   Some Convergence/Hessian Checks
##################################################
#Final maximum absolute gradient
CV_df$max_grad[ifold] <-
max(abs(fit_new$parameter_estimates$diagnostics$final_gradient))
#Is hessian is positive definite?
CV_df$pdHess[ifold] <- fit_new$parameter_estimates$SD$pdHess
#check_fit chekcs bounds, TRUE is bad and FALSE is good
CV_df$bound_check[ifold] <- check_fit(fit_new$parameter_estimates)
CV_df$pred_jnll[ifold] <- fit_new$Report$pred_jnll
##################################################
####   Calculate RRMSE
##################################################
withheld_idx <- which(fit_new$data_list$PredTF_i == T)
#Withheld data locations
withheld_df <- data.frame(
idx =  withheld_idx,
E_km = fit_new$spatial_list$loc_i[withheld_idx,'E_km'],
N_km = fit_new$spatial_list$loc_i[withheld_idx,'N_km'],
spp = 1+fit_new$data_frame$c_iz[withheld_idx],
year = 1+fit_new$data_list$t_iz[withheld_idx,1],
obs_density = (fit_new$data_frame$b_i/fit_new$data_frame$a_i)[withheld_idx]
)
#Grid locations
loc_g <- fit_new$spatial_list$loc_g
#Year indices
years = unique(withheld_df$year)
#which grids are closest to each withheld data location
grid_idx <- RANN::nn2(query = withheld_df[,c('E_km', 'N_km')],
data = loc_g,
k = 1)$nn.idx
#For each station, locate cell/spp/year density predictions that correspond
#to the location of the data
for (irow in 1:nrow(withheld_df)) {
withheld_df$pred_density[irow] <-
fit_new$Report$D_gcy[grid_idx[irow],
withheld_df$spp[irow],
withheld_df$year[irow]]
}
#Calculate the mean observed density for the calculation of the RRMSE
#There are many ways to do this and I chose for the normalizing constant to
#be specific to year and species.
mean_pred_density = aggregate(obs_density ~ spp + year, data = withheld_df,
FUN = mean)
#Calculate RRMSE for each year for each species using the mean observed
#density calculated above
for (ispp in 1:15) {
for (itime in 1:11) {
split_df <- subset(withheld_df,
spp == ispp & year == years[itime])
temp_RMSE <- sqrt(mean((split_df$obs_density - split_df$pred_density)^2))
temp_mean_pred_density <-
mean_pred_density[mean_pred_density$spp == ispp
& mean_pred_density$year == years[itime],
'obs_density']
RRMSE[ifold, ispp, itime] = temp_RMSE / temp_mean_pred_density
}
}
print(paste0('Done with fold ', ifold))
}
CV_df$pred_jnll
#Average RRMSE across years
round(apply(RRMSE, MARGIN = c(1:2), mean), 2)
CV_df
load("C:/Users/zack.oyafuso/Work/GitHub/Optimal_Allocation_GoA/model_10d/Spatiotemporal_Optimization/Str10Run8/result_list.RData")
result_list$CV_constraints
load("~/GitHub/Optimal_Allocation_GoA/model_10d/Survey_Comparison_Simulations/Survey_Simulation_Results.RData")
load("C:/Users/zack.oyafuso/GitHub/Optimal_Allocation_GoA/model_10d/Survey_Comparison_Simulations/Survey_Simulation_Results.RData")
load("C:/Users/zack.oyafuso/Work/GitHub/Optimal_Allocation_GoA/model_10d/Survey_Comparison_Simulations/Survey_Simulation_Results.RData")
load("C:/Users/zack.oyafuso/Work/GitHub/Optimal_Allocation_GoA/model_10d/Survey_Comparison_Simulations/Survey_Simulation_Results.RData")
result_list$CV_constraints
apply(Survey_true_cv_array[,,2], MARGIN = 2, median)
result_list$n
apply(Survey_rel_bias_est[,,2], MARGIN = 2, median)
load("C:/Users/zack.oyafuso/Work/GitHub/Optimal_Allocation_GoA/model_10d/Survey_Comparison_Simulations/SRS_Simulation_Results.RData")
load("C:/Users/zack.oyafuso/Work/GitHub/Optimal_Allocation_GoA/model_10d/Survey_Comparison_Simulations/Simple_RS_Simulation_Results.RData")
apply(SRS_true_cv_array[,,2], MARGIN = 2, median)
apply(SRS_rel_bias_est[,,2], MARGIN = 2, median)
apply(SRS_true_cv_array[,,2], MARGIN = 2, median)
result_list$CV_constraints
apply(SRS_true_cv_array[,,2], MARGIN = 2, median)
apply(Survey_true_cv_array[,,2], MARGIN = 2, median)
###############################################################################
## Project:       Spatiotemporal Survey Optimization
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Conduct SamplingStrata R package multispecies stratified
##                survey optimization
###############################################################################
rm(list = ls())
##################################################
####    Import required packages
##################################################
library(sp)
library(RColorBrewer)
library(raster)
##################################################
####   Set up directories
####
####   Set up some constants of the optimization
####   Flexible: Spatiotemporal Variance, species specific CV constraints
####   Spatial:  Spatial Variance, 1 CV constraint
####   Single_Species: Spatiotemporal Variance, univariate optimization,
####                   one CV constraint
##################################################
which_machine <- c("Zack_MAC"=1, "Zack_PC" =2, "Zack_GI_PC"=3)[3]
VAST_model <- "10d"
VAST_model <- "11"
SamplingStrata_dir <- paste0(c("/Users/zackoyafuso/",
"C:/Users/Zack Oyafuso/",
"C:/Users/zack.oyafuso/")[which_machine],
"Downloads/SamplingStrata-master/R")
which_method = c("Flexible" = 1,
"Spatial" = 2,
"Single_Species" = 3)[1]
github_dir <- paste0(c("/Users/zackoyafuso/Documents",
"C:/Users/Zack Oyafuso/Documents",
"C:/Users/zack.oyafuso/Work")[which_machine],
"/GitHub/Optimal_Allocation_GoA/model_",
VAST_model, "/",
c("Spatiotemporal_Optimization/",
"Spatial_Optimization/",
"Single_Species_Optimization/")[which_method])
##################################################
####   Load functions from SamplingStrata packages into global environment
####   Load modified buildStrataDF function if using spatiotemporal
####   stratum variance
##################################################
if (which_method %in% c(1,3)) {
for (ifile in dir(SamplingStrata_dir, full.names = T)) source(ifile)
source(paste0(dirname(dirname(github_dir)),
"/modified_functions/buildStrataDF_Zack.R"))
}
if (which_method %in% 2) {
library(SamplingStrata)
}
##################################################
####   Load Data
##################################################
load(paste0(dirname(github_dir), "/optimization_data.RData"))
load(paste0(dirname(dirname(github_dir)), "/data/Extrapolation_depths.RData"))
##################################################
####   If doing a survey comparison (for models 10x and 11)
####   Load Simulated Survey metrics for use in threshold levels
##################################################
if (VAST_model %in% c(paste0(10, letters[1:4]), '11') ) {
load(paste0(dirname(github_dir), "/Survey_Comparison_Simulations/",
"Survey_Simulation_Results.RData"))
}
stratas <- c(5,10,15,20,30,60)
ns <- c(15, 15, 1)[which_method]
##################################################
####   If Single_Species: subset just the one species
##################################################
SS_which_species <- 1 #which species are we doing?
if (which_method == 3) {
SS_which_species <- 1 #which species are we doing?
frame <- frame[,c("id", "X1", "X2", paste0("Y", SS_which_species),
"domainvalue")]
frame_raw <- frame_raw[,c("id", "X1", "X2",
paste0("Y", SS_which_species),
"domainvalue", "year")]
names(frame)[4] <- names(frame_raw)[4] <- "Y1"
}
##################################################
####  lower CV threshold
####  If doing a survey comparison, set to the median of the simulated surveys
####  Else: set to 0.10 for all scenarios (naive assumption)
##################################################
if (VAST_model %in% c(paste0(10, letters[1:4]), '11') ) {
threshold <- list(apply(Survey_true_cv_array,
MARGIN = 2:3, FUN = median),
apply(Survey_true_cv_array,
MARGIN = 2:3, FUN = median),
matrix(0, nrow = ns, ncol = 3))[[which_method]]
} else {
threshold <- matrix(0.1, nrow = ns, ncol = 3)
}
##################################################
####   Run optimization
##################################################
par(mfrow = c(6,6), mar = c(2,2,0,0))
for (istrata in 2) {
temp_strata <- stratas[istrata]
##Initial Condition
Run <- 1
isample <- 1
current_n <- 0
##Initial Upper CV constraints
if (VAST_model %in% c(paste0(10, letters[1:4]), '11') ) {
CV_constraints <- list(
rep(c(.4, 0.3, 0.2)[isample], ns),
rep(c(.4, 0.3, 0.2)[isample], ns),
c(0.09, 0.20, 0.10,
0.09, 0.15, 0.07,
0.05, 0.09, 0.15,
0.09, 0.20, 0.06,
0.30, 0.20, 0.06)[SS_which_species])[[which_method]]
creep_rate <- c(0.1, 0.05, 0.025)[isample]
} else {
CV_constraints <- list(
rep(c(.4, 0.3, 0.2)[isample], ns),
rep(c(.2, 0.15, 0.1)[isample], ns))[[which_method]]
creep_rate <- c(0.02, 0.01)[which_method]
}
#Create CV dataframe
cv <- list()
for (spp in 1:ns) cv[[paste0("CV", spp)]] <- as.numeric(CV_constraints[spp])
cv[["DOM"]] <- 1
cv[["domainvalue"]] <- 1
cv <- as.data.frame(cv)
while(current_n <= 820){ #Run until you reach 820 samples
#Set wd for output files, create a directory if it doesn"t exist yet
temp_dir = paste0(github_dir, "Str", temp_strata, "Run",Run)
if(!dir.exists(temp_dir)) dir.create(temp_dir)
setwd(temp_dir)
#Run optimization
solution <- optimStrata(method = "continuous",
errors = cv,
framesamp = frame,
iter = 200,
pops = 30,
elitism_rate = 0.1,
mut_chance = 1 / (temp_strata + 1),
nStrata = temp_strata,
showPlot = T,
parallel = F,
writeFiles = T)
sum_stats <- summaryStrata(solution$framenew,
solution$aggr_strata,
progress=FALSE)
#Plot Solution
goa <- SpatialPointsDataFrame(
coords = Extrapolation_depths[,c("E_km", "N_km")],
data = data.frame(Str_no = solution$framenew$STRATO) )
goa_ras <- raster(goa, resolution = 5)
goa_ras <- rasterize(x = goa, y = goa_ras, field = "Str_no")
png(filename = "solution.png", width = 5, height = 5, units = "in",
res = 500)
plot(goa_ras, axes = F,
col = terrain.colors(temp_strata)[sample(temp_strata)])
dev.off()
#Save Output
CV_constraints <- expected_CV(strata = solution$aggr_strata)
current_n <- sum(sum_stats$Allocation)
isample <- ifelse(current_n < 280, 1, #1 boat
ifelse(current_n < 550, 2, #2 boat
3)) #3 boat
result_list <- list(solution = solution,
sum_stats = sum_stats,
CV_constraints = CV_constraints,
n = current_n)
save(list = "result_list", file = "result_list.RData")
#Set up next run by changing upper CV constraints
#If doing a survey comparison, reduce CV proportionally
#Else: reduce CV absolutely
Run <- Run + 1
if (VAST_model %in% c(paste0(10, letters[1:4]), '11') ) {
creep_rate <- c(0.1, 0.05, 0.05)[isample]
CV_constraints <- CV_constraints * (1 - creep_rate)
} else {
CV_constraints <- CV_constraints - creep_rate
}
#Apply lower threshold: if CV is lower than the threshold, set CV to
#to the lower theshold
for (ispp in 1:ns) {
CV_constraints[ispp] <-
ifelse(CV_constraints[ispp]<threshold[ispp, isample],
threshold[ispp, isample],
CV_constraints[ispp])
}
#Create CV dataframe in the formmat of SamplingStrata
cv <- list()
for (spp in 1:ns) cv[[paste0("CV", spp)]] <- as.numeric(CV_constraints[spp])
cv[["DOM"]] <- 1
cv[["domainvalue"]] <- 1
cv <- as.data.frame(cv)
}
}
