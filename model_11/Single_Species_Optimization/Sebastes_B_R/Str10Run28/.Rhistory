##               Sebastes polyspinis
##               Run 5-fold Cross Validation for Each Model
###############################################################################
rm(list = ls())
## Author:       Zack Oyafuso (zack.oyafuso@noaa.gov)
## Contributors: Lewis Barnett (lewis.barnett@noaa.gov)
##               Jim Thorson's VAST wiki example
##           (https://github.com/James-Thorson-NOAA/VAST/wiki/Crossvalidation)
## Description:  Run single-species VAST models for
##               Sebastes variabilis
##               Sebastes aleutus
##               Sebastes polyspinis
##               Run 5-fold Cross Validation for Each Model
###############################################################################
rm(list = ls())
##################################################
####   Load packages
##################################################
library(VAST)
##################################################
####   Set up model settings
####   Create new directories for each model
####   Set up directories
##################################################
which_machine <- c("Zack_PC" = 1, "Zack_GI_PC" = 2)[2]
github_dir <- c("C:/Users/Zack Oyafuso/Documents/GitHub/MS_OM_GoA/",
'C:/Users/zack.oyafuso/Work/GitHub/MS_OM_GoA/')[which_machine]
VAST_dir <- c("C:/Users/Zack Oyafuso/Desktop/VAST_Runs/Single_Species/",
'G:/Oyafuso/VAST_Runs_EFH/Single_Species/')[which_machine]
##################################################
####   Import CPUE dataset, species set spreadsheet
##################################################
master_data <- read.csv(file = paste0(github_dir, 'data/GOA_multspp.csv') )
if (!dir.exists(VAST_dir)) dir.create(VAST_dir, recursive = T)
depth_in_model = F
which_spp =     'Sebastolobus alascanus'
#If depth covariates are in the model, import modified function
if (depth_in_model) source(paste0(github_dir, 'fit_model_X_GTP.R'))
result_dir <- paste0(VAST_dir, which_spp,
ifelse(depth_in_model,  '_depth', ''), '/')
if (!dir.exists(result_dir)) dir.create(result_dir)
##################################################
####   Subset species
##################################################
data <- subset(master_data,
SPECIES_NAME == which_spp)
data$SPECIES_NAME <- droplevels(data$SPECIES_NAME)
##################################################
####   Prepare the dataframe for catch-rate data in the VAST format
##################################################
Data_Geostat <- data.frame( "spp" = data$SPECIES_NAME,
"Year" = data$YEAR,
"Catch_KG" = data$WEIGHT,
"AreaSwept_km2" = data$EFFORT,
"Vessel" = 0,
"Lat" = data$LATITUDE,
"Lon" = data$LONGITUDE)
if (depth_in_model){
Data_Geostat[, c("LOG_DEPTH",
"LOG_DEPTH2") ] = data[, c('LOG_DEPTH_EFH_CEN',
'LOG_DEPTH_EFH_CEN_SQ')]
}
##################################################
####   Assign 10 fold partitions of the data
##################################################
n_fold <- 10
years <- paste0(unique(Data_Geostat$Year))
NTime <- length(unique(Data_Geostat$Year))
#Create unique stationID from the latlon. To make sure the ids are unique,
#we use the table function to make sure there are 7900 records (as of 2019)
Data_Geostat$latlon <- paste0(Data_Geostat$Lat, Data_Geostat$Lon)
table(table(Data_Geostat$latlon))
#split Data_Geostat by year, then on each year-split, randomly assign
#fold numbers to the each unique station
set.seed(2342)
foldno <- lapply(X = split.data.frame(Data_Geostat,
f = Data_Geostat$Year),
FUN = function(test) {
unique_loc <- unique(test$latlon)
fold_no <- sample(x = 1:n_fold,
size = length(unique_loc),
replace = T)
return(split(unique_loc, fold_no))
})
#Attach fold number to the Data_Geostat
for (iyear in years) {
for (ifold in paste(1:n_fold)) {
Data_Geostat[Data_Geostat$latlon %in% foldno[[iyear]][[ifold]] ,
'fold'] = as.integer(ifold)
}
}
##################################################
####   Spatial settings: The following settings define the spatial resolution
####   for the model, and whether to use a grid or mesh approximation
####   Stratification for results
##################################################
Method <- "Mesh"
strata.limits <- data.frame('STRATA' = c("All_areas"),
'west_border' = -Inf,
'east_border' = Inf)
settings <- FishStatsUtils::make_settings(
n_x = 500,   # Number of knots
Region='User',
purpose="index2",
strata.limits=strata.limits,
bias.correct=FALSE,
FieldConfig =  c("Omega1"=1, "Epsilon1"=1, "Omega2"=1, "Epsilon2"=1),
RhoConfig = c("Beta1"=0, "Beta2"=0, "Epsilon1"=0, "Epsilon2"=0),
OverdispersionConfig = c("Eta1"=0, "Eta2"=0),
ObsModel = c(2,0),
Options = c("SD_site_density" = 0,
"SD_site_logdensity" = 0,
"Project_factors" = 0),
use_anisotropy = T)
##################################################
####   Import "true" and not interpolated covariate
####   data if using depth covariates
##################################################
load( paste0(github_dir, 'data/Extrapolation_depths.RData'))
n_g <- nrow(Extrapolation_depths) #number of grid cells
n_t <- diff(range(Data_Geostat$Year)) + 1 #Number of total years
n_p <- 2 #two density covariates
X_gtp <- array(dim = c(n_g, n_t, n_p) )
for (i in 1:n_t) {
X_gtp[,i,] <-
as.matrix(Extrapolation_depths[,c('LOG_DEPTH_EFH_CEN',
'LOG_DEPTH_EFH_CEN_SQ')])
}
##################################################
####   Fit the model and save output
##################################################
load("G:/Oyafuso/VAST_Runs_EFH/Single_Species/Sebastolobus alascanus/fit.RData")
result_dir
# Loop through partitions, refitting each time with a different PredTF_i
for (fI in n_fold:7 ) {
PredTF_i <- ifelse( Data_Geostat$fold == fI, TRUE, FALSE )
if (!depth_in_model) {
# Refit, starting at MLE, without calculating standard errors (to save time)
fit_new = FishStatsUtils::fit_model(
"settings" = settings,
"working_dir" = paste0(result_dir,'CV_', fI),
"Lat_i" = Data_Geostat[, 'Lat'],
"Lon_i" = Data_Geostat[, 'Lon'],
"t_i" = Data_Geostat[, 'Year'],
"c_i" = as.numeric(Data_Geostat[, 'spp']) - 1,
"b_i" = Data_Geostat[, 'Catch_KG'],
"a_i" = Data_Geostat[, 'AreaSwept_km2'],
"v_i" = Data_Geostat[, 'Vessel'],
"PredTF_i" = PredTF_i,
"Parameters" = fit$ParHat,
"getsd" = T,
"silent" = T,
"max_cells" = Inf,
"test_fit" = F,
"newtonsteps" = 1,
"input_grid" = Extrapolation_depths)
}
if (depth_in_model) {
fit_new = fit_model(
"settings" = settings,
"working_dir" = paste0(result_dir, 'CV_', fI),
"Lat_i" = Data_Geostat[, 'Lat'],
"Lon_i" = Data_Geostat[, 'Lon'],
"t_i" = Data_Geostat[, 'Year'],
"c_i" = as.numeric(Data_Geostat[, 'spp']) - 1,
"b_i" = Data_Geostat[, 'Catch_KG'],
"a_i" = Data_Geostat[, 'AreaSwept_km2'],
"v_i" = Data_Geostat[, 'Vessel'],
"PredTF_i" = PredTF_i,
"Parameters" = fit$ParHat,
"getsd" = T,
"silent" = T,
"max_cells" = Inf,
"test_fit" = F,
"newtonsteps" = 1,
##Additional arguments for covariates
"formula" = "Catch_KG ~ LOG_DEPTH + LOG_DEPTH2",
"covariate_data" = cbind(Data_Geostat[,c('Lat',
'Lon',
'LOG_DEPTH',
'LOG_DEPTH2',
'Catch_KG')],
Year = NA),
"X_gtp" = X_gtp,
"input_grid" = Extrapolation_depths)
}
# Save fit
save(list = 'fit_new',
file = paste0(result_dir,'CV_', fI, '/fit.RData'))
}
str(fit_new$Report$D_gcy)
Sys.setenv(PATH=paste0(Sys.getenv("PATH"),";C:\\Rtools\\bin\\"))
install.packages("TMB")
install.packages("INLA", repos=c(getOption("repos"), INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
install.packages("rlang")
install.github("james-thorson/FishStatsUtils", INSTALL_opts="--no-staged-install")
install_github("james-thorson/FishStatsUtils", INSTALL_opts="--no-staged-install")
library(devtools)
install.packages("assertthat")
library(devtools)
install.packages("backports")
library(devtools)
install_github("james-thorson/FishStatsUtils", INSTALL_opts="--no-staged-install")
install_github("james-thorson/VAST", INSTALL_opts="--no-staged-install")
library(VAST)
###############################################################################
## Project:       Spatiotemporal Survey Optimization
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Conduct SamplingStrata R package multispecies stratified
##                survey optimization
###############################################################################
rm(list = ls())
##################################################
####    Import required packages
##################################################
library(sp)
library(RColorBrewer)
library(raster)
##################################################
####   Set up directories
####
####   Set up some constants of the optimization
####   Multispeceis: Spatiotemporal Variance, species specific CV constraints
####   Single_Species: Spatiotemporal Variance, univariate optimization,
##################################################
which_machine <- c("Zack_MAC" = 1, "Zack_PC" = 2, "Zack_GI_PC" = 3)[3]
VAST_model <- "11"
SamplingStrata_dir <- paste0(c("/Users/zackoyafuso/",
"C:/Users/Zack Oyafuso/",
"C:/Users/zack.oyafuso/")[which_machine],
"Downloads/SamplingStrata-master/R")
which_method = c("Multi_Species" = 1,
"Single_Species" = 2)[2]
github_dir <- paste0(c("/Users/zackoyafuso/Documents",
"C:/Users/Zack Oyafuso/Documents",
"C:/Users/zack.oyafuso/Work")[which_machine],
"/GitHub/Optimal_Allocation_GoA/model_",
VAST_model, "/",
c("Spatiotemporal_Optimization/",
"Single_Species_Optimization/")[which_method])
##################################################
####   Load functions from SamplingStrata packages into global environment
####   Load modified buildStrataDF function to incorporate spatiotemporal
####   stratum variance instead of spatial variance
##################################################
for (ifile in dir(SamplingStrata_dir, full.names = T)) source(ifile)
source(paste0(dirname(dirname(github_dir)),
"/modified_functions/buildStrataDF_Zack.R"))
##################################################
####   Load Data
####   Load Population CVs for use in the thresholds
##################################################
load(paste0(dirname(github_dir), "/optimization_data.RData"))
load(paste0(dirname(dirname(github_dir)), "/data/Extrapolation_depths.RData"))
load(paste0(dirname(github_dir), "/Population_Variances.RData"))
##################################################
####   Some Constants
##################################################
stratas <- c(5,10,15,20,30,60)
ns <- c(15, 1)[which_method]
##################################################
####   If Single_Species: subset just the one species
##################################################
if (which_method == 2) {
SS_which_species <- 11 #which species are we doing?
frame <- frame[,c("id", "X1", "X2", paste0("Y", SS_which_species),
"domainvalue")]
frame_raw <- frame_raw[,c("id", "X1", "X2",
paste0("Y", SS_which_species),
"domainvalue", "year")]
names(frame)[4] <- names(frame_raw)[4] <- "Y1"
github_dir = paste0(github_dir, gsub(x = sci_names[SS_which_species],
pattern = ' ',
replacement = '_'), '/')
if(!dir.exists(github_dir)) dir.create(github_dir)
# Lower CV threshold is not needed for a single-species analysis
threshold <- matrix(data = 0,
nrow = ns,
ncol = 3)
}
##################################################
####   Run optimization
##################################################
par(mfrow = c(6,6),
mar = c(2,2,0,0))
istrata = 2
temp_strata <- stratas[istrata]
##Initial Condition
Run <- 1
Run = 18
isample = 3
current_n <- 0
CV_constraints = .04752 * 0.95
#Create CV dataframe
cv <- list()
for (spp in 1:ns) cv[[paste0("CV", spp)]] <- as.numeric(CV_constraints[spp])
cv[["DOM"]] <- 1
cv[["domainvalue"]] <- 1
cv <- as.data.frame(cv)
Run
while(current_n <= 820){ #Run until you reach 820 samples
#Set wd for output files, create a directory if it doesn"t exist yet
temp_dir = paste0(github_dir, "Str", temp_strata, "Run", Run)
if(!dir.exists(temp_dir)) dir.create(temp_dir)
setwd(temp_dir)
#Run optimization
solution <- optimStrata(method = "continuous",
errors = cv,
framesamp = frame,
iter = 300,
pops = 50,
elitism_rate = 0.1,
mut_chance = 1 / (temp_strata + 1),
nStrata = temp_strata,
showPlot = T,
writeFiles = T)
sum_stats <- summaryStrata(solution$framenew,
solution$aggr_strata,
progress=FALSE)
#Plot Solution
goa <- SpatialPointsDataFrame(
coords = Extrapolation_depths[,c("E_km", "N_km")],
data = data.frame(Str_no = solution$framenew$STRATO) )
goa_ras <- raster(goa, resolution = 5)
goa_ras <- rasterize(x = goa, y = goa_ras, field = "Str_no")
png(filename = "solution.png", width = 5, height = 5, units = "in",
res = 500)
plot(goa_ras, axes = F,
col = terrain.colors(temp_strata)[sample(temp_strata)])
dev.off()
#Save Output
CV_constraints <- expected_CV(strata = solution$aggr_strata)
current_n <- sum(sum_stats$Allocation)
isample <- ifelse(current_n < 280, 1, #1 boat
ifelse(current_n < 550, 2, #2 boat
3)) #3 boat
result_list <- list(solution = solution,
sum_stats = sum_stats,
CV_constraints = CV_constraints,
n = current_n)
save(list = "result_list", file = "result_list.RData")
#Set up next run by changing upper CV constraints
#If doing a survey comparison, reduce CV proportionally
#Else: reduce CV absolutely
Run <- Run + 1
creep_rate <- c(0.1, 0.05, 0.01)[isample]
CV_constraints <- CV_constraints * (1 - creep_rate)
#Apply lower threshold: if CV is lower than the threshold, set CV to
#to the lower theshold
for (ispp in 1:ns) {
CV_constraints[ispp] <-
ifelse(CV_constraints[ispp]<threshold[ispp, isample],
threshold[ispp, isample],
CV_constraints[ispp])
}
#Create CV dataframe in the formmat of SamplingStrata
cv <- list()
for (spp in 1:ns) cv[[paste0("CV", spp)]] <- as.numeric(CV_constraints[spp])
cv[["DOM"]] <- 1
cv[["domainvalue"]] <- 1
cv <- as.data.frame(cv)
}
CV_constraints
CV_constraints * 0.95
CV_constraints = CV_constraints * 0.95
#Create CV dataframe
cv <- list()
for (spp in 1:ns) cv[[paste0("CV", spp)]] <- as.numeric(CV_constraints[spp])
cv[["DOM"]] <- 1
cv[["domainvalue"]] <- 1
cv <- as.data.frame(cv)
while(current_n <= 820){ #Run until you reach 820 samples
#Set wd for output files, create a directory if it doesn"t exist yet
temp_dir = paste0(github_dir, "Str", temp_strata, "Run", Run)
if(!dir.exists(temp_dir)) dir.create(temp_dir)
setwd(temp_dir)
#Run optimization
solution <- optimStrata(method = "continuous",
errors = cv,
framesamp = frame,
iter = 300,
pops = 50,
elitism_rate = 0.1,
mut_chance = 1 / (temp_strata + 1),
nStrata = temp_strata,
showPlot = T,
writeFiles = T)
sum_stats <- summaryStrata(solution$framenew,
solution$aggr_strata,
progress=FALSE)
#Plot Solution
goa <- SpatialPointsDataFrame(
coords = Extrapolation_depths[,c("E_km", "N_km")],
data = data.frame(Str_no = solution$framenew$STRATO) )
goa_ras <- raster(goa, resolution = 5)
goa_ras <- rasterize(x = goa, y = goa_ras, field = "Str_no")
png(filename = "solution.png", width = 5, height = 5, units = "in",
res = 500)
plot(goa_ras, axes = F,
col = terrain.colors(temp_strata)[sample(temp_strata)])
dev.off()
#Save Output
CV_constraints <- expected_CV(strata = solution$aggr_strata)
current_n <- sum(sum_stats$Allocation)
isample <- ifelse(current_n < 280, 1, #1 boat
ifelse(current_n < 550, 2, #2 boat
3)) #3 boat
result_list <- list(solution = solution,
sum_stats = sum_stats,
CV_constraints = CV_constraints,
n = current_n)
save(list = "result_list", file = "result_list.RData")
#Set up next run by changing upper CV constraints
#If doing a survey comparison, reduce CV proportionally
#Else: reduce CV absolutely
Run <- Run + 1
creep_rate <- c(0.1, 0.05, 0.01)[isample]
CV_constraints <- CV_constraints * (1 - creep_rate)
#Apply lower threshold: if CV is lower than the threshold, set CV to
#to the lower theshold
for (ispp in 1:ns) {
CV_constraints[ispp] <-
ifelse(CV_constraints[ispp]<threshold[ispp, isample],
threshold[ispp, isample],
CV_constraints[ispp])
}
#Create CV dataframe in the formmat of SamplingStrata
cv <- list()
for (spp in 1:ns) cv[[paste0("CV", spp)]] <- as.numeric(CV_constraints[spp])
cv[["DOM"]] <- 1
cv[["domainvalue"]] <- 1
cv <- as.data.frame(cv)
}
creep_rate <- c(0.1, 0.05, 0.025)[isample]
CV_constraints <- CV_constraints * (1 - creep_rate)
#Apply lower threshold: if CV is lower than the threshold, set CV to
#to the lower theshold
for (ispp in 1:ns) {
CV_constraints[ispp] <-
ifelse(CV_constraints[ispp]<threshold[ispp, isample],
threshold[ispp, isample],
CV_constraints[ispp])
}
#Create CV dataframe in the formmat of SamplingStrata
cv <- list()
for (spp in 1:ns) cv[[paste0("CV", spp)]] <- as.numeric(CV_constraints[spp])
cv[["DOM"]] <- 1
cv[["domainvalue"]] <- 1
cv <- as.data.frame(cv)
cv
while(current_n <= 820){ #Run until you reach 820 samples
#Set wd for output files, create a directory if it doesn"t exist yet
temp_dir = paste0(github_dir, "Str", temp_strata, "Run", Run)
if(!dir.exists(temp_dir)) dir.create(temp_dir)
setwd(temp_dir)
#Run optimization
solution <- optimStrata(method = "continuous",
errors = cv,
framesamp = frame,
iter = 300,
pops = 50,
elitism_rate = 0.1,
mut_chance = 1 / (temp_strata + 1),
nStrata = temp_strata,
showPlot = T,
writeFiles = T)
sum_stats <- summaryStrata(solution$framenew,
solution$aggr_strata,
progress=FALSE)
#Plot Solution
goa <- SpatialPointsDataFrame(
coords = Extrapolation_depths[,c("E_km", "N_km")],
data = data.frame(Str_no = solution$framenew$STRATO) )
goa_ras <- raster(goa, resolution = 5)
goa_ras <- rasterize(x = goa, y = goa_ras, field = "Str_no")
png(filename = "solution.png", width = 5, height = 5, units = "in",
res = 500)
plot(goa_ras, axes = F,
col = terrain.colors(temp_strata)[sample(temp_strata)])
dev.off()
#Save Output
CV_constraints <- expected_CV(strata = solution$aggr_strata)
current_n <- sum(sum_stats$Allocation)
isample <- ifelse(current_n < 280, 1, #1 boat
ifelse(current_n < 550, 2, #2 boat
3)) #3 boat
result_list <- list(solution = solution,
sum_stats = sum_stats,
CV_constraints = CV_constraints,
n = current_n)
save(list = "result_list", file = "result_list.RData")
#Set up next run by changing upper CV constraints
#If doing a survey comparison, reduce CV proportionally
#Else: reduce CV absolutely
Run <- Run + 1
creep_rate <- c(0.1, 0.05, 0.025)[isample]
CV_constraints <- CV_constraints * (1 - creep_rate)
#Apply lower threshold: if CV is lower than the threshold, set CV to
#to the lower theshold
for (ispp in 1:ns) {
CV_constraints[ispp] <-
ifelse(CV_constraints[ispp]<threshold[ispp, isample],
threshold[ispp, isample],
CV_constraints[ispp])
}
#Create CV dataframe in the formmat of SamplingStrata
cv <- list()
for (spp in 1:ns) cv[[paste0("CV", spp)]] <- as.numeric(CV_constraints[spp])
cv[["DOM"]] <- 1
cv[["domainvalue"]] <- 1
cv <- as.data.frame(cv)
}
