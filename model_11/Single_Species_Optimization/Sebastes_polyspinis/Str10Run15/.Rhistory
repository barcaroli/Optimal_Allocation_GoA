load(paste0(VAST_dir, "/fit.RData"))
load(paste0(github_dir, "data/Extrapolation_depths.RData"))
spp_df <- read.csv(file = paste0(github_dir, "data/spp_df.csv"),
check.names = F,
header = T,
row.names = "modelno")
##################################################
####   Constants
##################################################
## Index years that had data
# Year_Set <- seq(min(fit$data_frame[,"t_i"]),
#                max(fit$data_frame[,"t_i"]))
# Years2Include <- which( Year_Set %in% sort(unique(fit$data_frame[,"t_i"])))
Year_Set <- 1996:2019
Years2Include <- c(1,  4,  8, 10, 12, 14, 16, 18, 20, 22, 24)
NTime <- length(Years2Include)
#Number of sampling grids
N <- nrow(Extrapolation_depths)
#Species names
which_spp_idx <- unlist(spp_df[VAST_model,])
sci_names <- sort( names(spp_df)[which_spp_idx] )
ns <- length(sci_names)
#Sample sizes
samples <- c(280, 550, 820)
nboats <- length(samples)
#Number of times to simulate survey
Niters <- 1000
stratas <- c(5, 10, 15, 20, 30, 60)
NStrata <- length(stratas)
##################################################
####   Create the data inputs to SamplingStrata
##################################################
df <- df_raw <- NULL
##################################################
####   Mean density across years
##################################################
df <- cbind(
data.frame(Domain = 1,
x = 1:N,
lon = Extrapolation_depths$E_km - min(Extrapolation_depths$E_km),
depth = Extrapolation_depths$DEPTH_EFH),
#Mean Density across years
apply(X = fit$Report$D_gct[,,Years2Include],
MARGIN = 1:2,
FUN = mean )
)
names(df)[-(1:4)] <- gsub(x = sci_names, pattern = " ", replacement = "_")
frame <- SamplingStrata::buildFrameDF(df = df,
id = "x",
X = c("depth", "lon"),
Y = gsub(x = sci_names,
pattern = " ",
replacement = "_"),
domainvalue = "Domain")
##################################################
####   Predicted density for each observed year and cell
##################################################
for (iT in 1:NTime) {
df_raw <- rbind(df_raw, cbind(
data.frame(Domain = 1,
x = 1:N,
year = iT,
lon = Extrapolation_depths$E_km - min(Extrapolation_depths$E_km),
depth = Extrapolation_depths$DEPTH_EFH),
fit$Report$D_gct[,,Years2Include[iT]] )
)
}
names(df_raw)[-(1:5)] <- gsub(x = sci_names, pattern = " ", replacement = "_")
frame_raw <- SamplingStrata::buildFrameDF(df = df_raw,
id = "x",
X = c("depth", "lon"),
Y = gsub(x = sci_names,
pattern = " ",
replacement = "_"),
domainvalue = "Domain")
##################################################
####   Calculate "true" mean density and "true" abundance index
##################################################
frame_raw$year <- rep(x = 1:NTime, each = N)
stmt <- paste0("aggregate(cbind(",
paste0("Y", 1:(ns-1), sep = ",", collapse = ""), "Y",ns,
") ~ year, data = frame_raw, FUN = mean)")
true_mean <- eval(parse(text = stmt))[,-1]
colnames(true_mean) <- sci_names
true_index <- t(apply(X = fit$Report$Index[,, Years2Include],
MARGIN = 2:3,
FUN = sum))
##################################################
####   Save Data
##################################################
save(list = c("frame", "frame_raw", "true_mean", "true_index", "ns",
"Years2Include","NTime", "N", "sci_names", "samples", "nboats",
"Niters", "stratas", "NStrata"),
file = paste0(github_dir, "model_", VAST_model,
"/optimization_data.RData"))
###############################################################################
## Project:       Calculate Population Variances
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Calculate population variances for different sampling schemes
##                Simple Random Sampling
##                Current Stratified Random Sampling Design
##                These population variances are more comparable to the
##                optimization, as the optimization is
###############################################################################
rm(list = ls())
##################################################
####   Import Libraries
##################################################
library(VAST)
library(readxl)
library(rgdal)
library(spatialEco)
##################################################
####   Set up directories
##################################################
which_machine <- c('Zack_MAC' = 1, 'Zack_PC' = 2, 'Zack_GI_PC' = 3)[3]
VAST_model <- "11"
github_dir <- paste0(c('/Users/zackoyafuso/Documents/',
'C:/Users/Zack Oyafuso/Documents/',
'C:/Users/zack.oyafuso/Work/')[which_machine],
"GitHub/Optimal_Allocation_GoA/model_", VAST_model, "/")
##################################
## Import Operating Model
##################################
load("G:/Oyafuso/VAST_Runs_EFH/VAST_output11/fit.RData")
load(paste0(dirname(github_dir), "/data/Extrapolation_depths.RData") )
load(paste0(github_dir, 'optimization_data.RData'))
##################################
## Import Strata Allocations and spatial grid and predicted density
##################################
GOA_allocations <- readxl::read_xlsx(
path = paste0(dirname(github_dir),
'/data/GOA 2019 stations by stratum.xlsx')
)
GOA_allocations3 <- readxl::read_xlsx(
path = paste0(dirname(github_dir),
'/data/GOA2019_ 3 boat_825_RNDM_stations.xlsx')
)
##################################################
####   Create dataframe of effort allocations across boats
##################################################
allocations <- data.frame(Stratum = sort(unique(GOA_allocations3$stratum)),
boat3 = aggregate(id ~ stratum,
data = GOA_allocations3,
FUN = length)$id,
boat2 = c(GOA_allocations$`Number stations`,
rep(0,5)))
allocations$boat1 = ceiling(allocations$boat2 / 2)
allocations$boat1 = ifelse(allocations$boat1 == 0, 0,
ifelse(allocations$boat1 == 1, 2,
allocations$boat1))
##################################################
####   Attribute each grid point to the current stratification
##################################################
goa_grid <- rgdal::readOGR(
"C:/Users/zack.oyafuso/Work/GitHub/MS_OM_GoA/data/shapefiles/goa_strata.shp")
goa_grid = sp::spTransform(x = goa_grid,
CRSobj = "+proj=utm +zone=5N +units=km")
temp <- spatialEco::point.in.poly(
x = SpatialPoints(coords = Extrapolation_depths[, c("E_km", "N_km")],
proj4string=CRS("+proj=utm +zone=5N +units=km")),
y = goa_grid)
plot(subset(goa_grid, STRATUM != 0),
col = terrain.colors(100)[sample(60)],
border = F)
plot(subset(goa_grid, STRATUM == 0), col = "brown", add = T)
points(temp,
pch = 16,
cex = 0.5)
points(subset(temp, STRATUM == 0), col = 'red')
##################################
## Calculate Population CVs under Simple Random Sampling
##################################
SRS_Pop_CV <- Current_STRS_Pop_CV <- matrix(nrow = ns,
ncol = nboats,
dimnames = list(sci_names, NULL))
for (ispp in 1:15) {
SRS_var = var(as.vector(fit$Report$D_gcy[, ispp, Years2Include]))
SRS_mean = mean(as.vector(fit$Report$D_gcy[, ispp, Years2Include]))
SRS_CV = sqrt(SRS_var / samples) / SRS_mean
SRS_Pop_CV[ispp, ] <- SRS_CV
}
##################################
## Calculate Population CVs under current STRS sampling
##################################
for (isample in 1:nboats) {
#Adjust sample size proportionally
nh <- allocations[, paste0('boat', isample)]
sampled_strata <- nh > 0
nstrata <- sum(sampled_strata)
nh <- nh[sampled_strata]
#strata constraints
Nh <- table(temp$STRATUM)[paste(allocations$Stratum[sampled_strata])]
Wh <- Nh / N
wh <- nh / Nh
#Calculate Total Mean, Variance, CV
stratano = rep(temp@data$STRATUM, 11)
stmt <- paste0('aggregate(cbind(',
paste0('Y', 1:(ns-1), sep = ',', collapse = ''), 'Y',ns,
") ~ stratano, data = frame_raw, FUN = mean)")
strata_mean <- eval(parse(text = stmt))
strata_mean <- subset(strata_mean, stratano %in% allocations$Stratum)[,-1]
strata_mean <- strata_mean[sampled_strata,]
stmt <- paste0('aggregate(cbind(',
paste0('Y', 1:(ns-1), sep = ',', collapse = ''), 'Y',ns,
") ~ stratano, data = frame_raw, FUN = var)")
strata_var <- eval(parse(text = stmt))
strata_var <- subset(strata_var, stratano %in% allocations$Stratum)[,-1]
strata_var <- strata_var[sampled_strata,]
#Calculate Total Mean, Variance, CV
SRS_var <- colSums(sweep(x = strata_var,
MARGIN = 1,
STATS = Wh^2 * (1 - wh) / nh,
FUN = '*'))
SRS_mean <- colSums(sweep(x = strata_mean,
MARGIN = 1,
STATS = Wh,
FUN = '*'))
strata_cv <- sqrt(SRS_var) / SRS_mean
Current_STRS_Pop_CV[, isample ] <- strata_cv
}
SRS_Pop_CV
###############################################################################
## Project:       Calculate Population Variances
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Calculate population variances for different sampling schemes
##                Simple Random Sampling
##                Current Stratified Random Sampling Design
##                These population variances are more comparable to the
##                optimization, as the optimization is
###############################################################################
rm(list = ls())
##################################################
####   Import Libraries
##################################################
library(VAST)
library(readxl)
library(rgdal)
library(spatialEco)
##################################################
####   Set up directories
##################################################
which_machine <- c('Zack_MAC' = 1, 'Zack_PC' = 2, 'Zack_GI_PC' = 3)[3]
VAST_model <- "11"
github_dir <- paste0(c('/Users/zackoyafuso/Documents/',
'C:/Users/Zack Oyafuso/Documents/',
'C:/Users/zack.oyafuso/Work/')[which_machine],
"GitHub/Optimal_Allocation_GoA/model_", VAST_model, "/")
##################################
## Import Operating Model
##################################
load("G:/Oyafuso/VAST_Runs_EFH/VAST_output11/fit.RData")
load(paste0(dirname(github_dir), "/data/Extrapolation_depths.RData") )
load(paste0(github_dir, 'optimization_data.RData'))
##################################
## Import Strata Allocations and spatial grid and predicted density
##################################
GOA_allocations <- readxl::read_xlsx(
path = paste0(dirname(github_dir),
'/data/GOA 2019 stations by stratum.xlsx')
)
GOA_allocations3 <- readxl::read_xlsx(
path = paste0(dirname(github_dir),
'/data/GOA2019_ 3 boat_825_RNDM_stations.xlsx')
)
##################################################
####   Create dataframe of effort allocations across boats
##################################################
allocations <- data.frame(Stratum = sort(unique(GOA_allocations3$stratum)),
boat3 = aggregate(id ~ stratum,
data = GOA_allocations3,
FUN = length)$id,
boat2 = c(GOA_allocations$`Number stations`,
rep(0,5)))
allocations$boat1 = ceiling(allocations$boat2 / 2)
allocations$boat1 = ifelse(allocations$boat1 == 0, 0,
ifelse(allocations$boat1 == 1, 2,
allocations$boat1))
##################################################
####   Attribute each grid point to the current stratification
##################################################
goa_grid <- rgdal::readOGR(
"C:/Users/zack.oyafuso/Work/GitHub/MS_OM_GoA/data/shapefiles/goa_strata.shp")
goa_grid = sp::spTransform(x = goa_grid,
CRSobj = "+proj=utm +zone=5N +units=km")
temp <- spatialEco::point.in.poly(
x = SpatialPoints(coords = Extrapolation_depths[, c("E_km", "N_km")],
proj4string=CRS("+proj=utm +zone=5N +units=km")),
y = goa_grid)
plot(subset(goa_grid, STRATUM != 0),
col = terrain.colors(100)[sample(60)],
border = F)
plot(subset(goa_grid, STRATUM == 0), col = "brown", add = T)
points(temp,
pch = 16,
cex = 0.5)
points(subset(temp, STRATUM == 0), col = 'red')
##################################
## Calculate Population CVs under Simple Random Sampling
##################################
SRS_Pop_CV <- Current_STRS_Pop_CV <- matrix(nrow = ns,
ncol = nboats,
dimnames = list(sci_names, NULL))
for (ispp in 1:15) {
SRS_var = var(as.vector(fit$Report$D_gct[, ispp, Years2Include]))
SRS_mean = mean(as.vector(fit$Report$D_gct[, ispp, Years2Include]))
SRS_CV = sqrt(SRS_var / samples) / SRS_mean
SRS_Pop_CV[ispp, ] <- SRS_CV
}
SRS_Pop_CV
round(SRS_Pop_CV, 2)
for (isample in 1:nboats) {
#Adjust sample size proportionally
nh <- allocations[, paste0('boat', isample)]
sampled_strata <- nh > 0
nstrata <- sum(sampled_strata)
nh <- nh[sampled_strata]
#strata constraints
Nh <- table(temp$STRATUM)[paste(allocations$Stratum[sampled_strata])]
Wh <- Nh / N
wh <- nh / Nh
#Calculate Total Mean, Variance, CV
stratano = rep(temp@data$STRATUM, 11)
stmt <- paste0('aggregate(cbind(',
paste0('Y', 1:(ns-1), sep = ',', collapse = ''), 'Y',ns,
") ~ stratano, data = frame_raw, FUN = mean)")
strata_mean <- eval(parse(text = stmt))
strata_mean <- subset(strata_mean, stratano %in% allocations$Stratum)[,-1]
strata_mean <- strata_mean[sampled_strata,]
stmt <- paste0('aggregate(cbind(',
paste0('Y', 1:(ns-1), sep = ',', collapse = ''), 'Y',ns,
") ~ stratano, data = frame_raw, FUN = var)")
strata_var <- eval(parse(text = stmt))
strata_var <- subset(strata_var, stratano %in% allocations$Stratum)[,-1]
strata_var <- strata_var[sampled_strata,]
#Calculate Total Mean, Variance, CV
SRS_var <- colSums(sweep(x = strata_var,
MARGIN = 1,
STATS = Wh^2 * (1 - wh) / nh,
FUN = '*'))
SRS_mean <- colSums(sweep(x = strata_mean,
MARGIN = 1,
STATS = Wh,
FUN = '*'))
strata_cv <- sqrt(SRS_var) / SRS_mean
Current_STRS_Pop_CV[, isample ] <- strata_cv
}
Current_STRS_Pop_CV
round(Current_STRS_Pop_CV)
round(Current_STRS_Pop_CV, 2)
###############################################################################
## Project:       Spatiotemporal Survey Optimization
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Conduct SamplingStrata R package multispecies stratified
##                survey optimization
###############################################################################
rm(list = ls())
##################################################
####    Import required packages
##################################################
library(sp)
library(RColorBrewer)
library(raster)
##################################################
####   Set up directories
####
####   Set up some constants of the optimization
####   Multispeceis: Spatiotemporal Variance, species specific CV constraints
####   Single_Species: Spatiotemporal Variance, univariate optimization,
##################################################
which_machine <- c("Zack_MAC" = 1, "Zack_PC" = 2, "Zack_GI_PC" = 3)[3]
VAST_model <- "11"
SamplingStrata_dir <- paste0(c("/Users/zackoyafuso/",
"C:/Users/Zack Oyafuso/",
"C:/Users/zack.oyafuso/")[which_machine],
"Downloads/SamplingStrata-master/R")
which_method = c("Multi_Species" = 1,
"Single_Species" = 2)[2]
github_dir <- paste0(c("/Users/zackoyafuso/Documents",
"C:/Users/Zack Oyafuso/Documents",
"C:/Users/zack.oyafuso/Work")[which_machine],
"/GitHub/Optimal_Allocation_GoA/model_",
VAST_model, "/",
c("Spatiotemporal_Optimization/",
"Single_Species_Optimization/")[which_method])
##################################################
####   Load functions from SamplingStrata packages into global environment
####   Load modified buildStrataDF function to incorporate spatiotemporal
####   stratum variance instead of spatial variance
##################################################
for (ifile in dir(SamplingStrata_dir, full.names = T)) source(ifile)
source(paste0(dirname(dirname(github_dir)),
"/modified_functions/buildStrataDF_Zack.R"))
##################################################
####   Load Data
####   Load Population CVs for use in the thresholds
##################################################
load(paste0(dirname(github_dir), "/optimization_data.RData"))
load(paste0(dirname(dirname(github_dir)), "/data/Extrapolation_depths.RData"))
load(paste0(dirname(github_dir), "/Population_Variances.RData"))
##################################################
####   Some Constants
##################################################
stratas <- c(5,10,15,20,30,60)
ns <- c(15, 1)[which_method]
##################################################
####   If Single_Species: subset just the one species
##################################################
if (which_method == 2) {
SS_which_species <- 13 #which species are we doing?
frame <- frame[,c("id", "X1", "X2", paste0("Y", SS_which_species),
"domainvalue")]
frame_raw <- frame_raw[,c("id", "X1", "X2",
paste0("Y", SS_which_species),
"domainvalue", "year")]
names(frame)[4] <- names(frame_raw)[4] <- "Y1"
github_dir = paste0(github_dir, gsub(x = sci_names[SS_which_species],
pattern = ' ',
replacement = '_'), '/')
if(!dir.exists(github_dir)) dir.create(github_dir)
# Lower CV threshold is not needed for a single-species analysis
threshold <- matrix(data = 0,
nrow = ns,
ncol = 3)
}
load("~/GitHub/Optimal_Allocation_GoA/model_11/Single_Species_Optimization/Sebastes_polyspinis/Str10Run1/result_list.RData")
result_list$CV_constraints
result_list$n
source('~/GitHub/Optimal_Allocation_GoA/Survey_Optimization.R', echo=TRUE)
source('~/GitHub/Optimal_Allocation_GoA/Survey_Optimization.R', echo=TRUE)
source('~/GitHub/Optimal_Allocation_GoA/Survey_Optimization.R', echo=TRUE)
source('~/GitHub/Optimal_Allocation_GoA/Survey_Optimization.R', echo=TRUE)
creep_rate <- c(0.1, 0.05, 0.05)[isample]
CV_constraints <- CV_constraints * (1 - creep_rate)
#Apply lower threshold: if CV is lower than the threshold, set CV to
#to the lower theshold
for (ispp in 1:ns) {
CV_constraints[ispp] <-
ifelse(CV_constraints[ispp]<threshold[ispp, isample],
threshold[ispp, isample],
CV_constraints[ispp])
}
#Create CV dataframe in the formmat of SamplingStrata
cv <- list()
for (spp in 1:ns) cv[[paste0("CV", spp)]] <- as.numeric(CV_constraints[spp])
cv[["DOM"]] <- 1
cv[["domainvalue"]] <- 1
cv <- as.data.frame(cv)
expected_CV(strata = solution$aggr_strata)
cv
while (current_n <= 820) { #Run until you reach 820 samples
#Set wd for output files, create a directory if it doesn"t exist yet
temp_dir = paste0(github_dir, "Str", temp_strata, "Run",Run)
if(!dir.exists(temp_dir)) dir.create(temp_dir)
setwd(temp_dir)
#Run optimization
solution <- optimStrata(method = "continuous",
errors = cv,
framesamp = frame,
iter = 300,
pops = 50,
elitism_rate = 0.1,
mut_chance = 1 / (temp_strata + 1),
nStrata = temp_strata,
showPlot = T,
writeFiles = T)
sum_stats <- summaryStrata(solution$framenew,
solution$aggr_strata,
progress=FALSE)
#Plot Solution
goa <- SpatialPointsDataFrame(
coords = Extrapolation_depths[,c("E_km", "N_km")],
data = data.frame(Str_no = solution$framenew$STRATO) )
goa_ras <- raster(goa, resolution = 5)
goa_ras <- rasterize(x = goa, y = goa_ras, field = "Str_no")
png(filename = "solution.png", width = 5, height = 5, units = "in",
res = 500)
plot(goa_ras, axes = F,
col = terrain.colors(temp_strata)[sample(temp_strata)])
dev.off()
#Save Output
CV_constraints <- expected_CV(strata = solution$aggr_strata)
current_n <- sum(sum_stats$Allocation)
isample <- ifelse(current_n < 280, 1, #1 boat
ifelse(current_n < 550, 2, #2 boat
3)) #3 boat
result_list <- list(solution = solution,
sum_stats = sum_stats,
CV_constraints = CV_constraints,
n = current_n)
save(list = "result_list", file = "result_list.RData")
#Set up next run by changing upper CV constraints
#If doing a survey comparison, reduce CV proportionally
#Else: reduce CV absolutely
Run <- Run + 1
creep_rate <- c(0.1, 0.05, 0.05)[isample]
CV_constraints <- CV_constraints * (1 - creep_rate)
#Apply lower threshold: if CV is lower than the threshold, set CV to
#to the lower theshold
for (ispp in 1:ns) {
CV_constraints[ispp] <-
ifelse(CV_constraints[ispp]<threshold[ispp, isample],
threshold[ispp, isample],
CV_constraints[ispp])
}
#Create CV dataframe in the formmat of SamplingStrata
cv <- list()
for (spp in 1:ns) cv[[paste0("CV", spp)]] <- as.numeric(CV_constraints[spp])
cv[["DOM"]] <- 1
cv[["domainvalue"]] <- 1
cv <- as.data.frame(cv)
}
