for (ispp in sort(unique(master_settings$ispp)) ) {
for (isample in samples) {
#Find solution closet to isample, append to sol_idx
sol_idx <- c(sol_idx,
with(master_settings[master_settings$ispp == ispp, ],
id[which.min(abs(n - isample))])
)
}
}
settings <- master_settings[sol_idx, 1:4]
res_df <- master_res_df[, 1 + sol_idx]
strata_list <- master_strata_list[sol_idx]
strata_stats_list <- master_strata_stats_list[sol_idx]
settings
###############################################################################
## Project:       Knitting Result for univariate STRS optimization
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:
###############################################################################
rm(list = ls())
###############################
## Set up directories
###############################
which_machine <- c("Zack_MAC" = 1, "Zack_PC" = 2, "Zack_GI_PC" = 3)[3]
github_dir <- paste0(c("/Users/zackoyafuso/Documents",
"C:/Users/Zack Oyafuso/Documents",
"C:/Users/zack.oyafuso/Work")[which_machine],
"/GitHub/Optimal_Allocation_GoA/")
###############################
## Import required packages
###############################
library(sp)
library(RColorBrewer)
library(raster)
###########################
## Load Data
###########################
load(paste0(github_dir, "/data/optimization_data.RData"))
load(paste0(github_dir, "/data/Extrapolation_depths.RData"))
###########################
## Empty Result objects
###########################
master_res_df <- data.frame(id = 1:N)
master_settings <- data.frame()
master_strata_list <- master_strata_stats_list <- list()
master_tradeoff <- list()
istrata <- 10
##########################
##########################
for (ispp in 1:ns_opt) {
for (iboat in 1:nboats) {
## For a given species and boat scenario, collect all runs
runs = dir(paste0(github_dir,
"results/Single_Species_Optimization/",
gsub(x = sci_names_opt[ispp],
pattern = " ",
replacement = "_"),
"/boat", iboat),
full.names = T)
nruns = length(runs)
## For each run
if (nruns > 0) {
for (irun in 1:nruns) {
#Load run
temp_file <- paste0(github_dir,
"results/Single_Species_Optimization/",
gsub(x = sci_names_opt[ispp],
pattern = " ",
replacement = "_"),
"/boat", iboat,
"/Str", istrata, "Run", irun, "/result_list.RData")
if (file.exists(temp_file)) {
load(temp_file)
#master_settings: result of optimization (CV, sample size)
master_settings <- rbind(
master_settings,
data.frame(iboat = iboat,
ispp = ispp,
n = result_list$n,
cv = as.numeric(result_list[[3]]))
)
#master_res_df: solution (which cell belongs to which stratum?)
master_res_df <- cbind(master_res_df,
result_list[[1]]$indices$X1)
#master_strata_list: stratum-level details of solution
master_strata_list <- c(master_strata_list,
list(result_list[[2]]))
#master_strata_stats_list: stratum-level means and variances
master_strata_stats_list <- c(master_strata_stats_list,
list(result_list$solution$aggr_strata))
}
}
}
}
}
####################################
## Subset those solutions that correspond to 1, 2, and 3 boats
####################################
master_settings$id = 1:nrow(master_settings)
sol_idx <- c()
for (ispp in sort(unique(master_settings$ispp)) ) {
for (isample in samples) {
#Find solution closet to isample, append to sol_idx
sol_idx <- c(sol_idx,
with(master_settings[master_settings$ispp == ispp, ],
id[which.min(abs(n - isample))])
)
}
}
settings <- master_settings[sol_idx, 1:4]
res_df <- master_res_df[, 1 + sol_idx]
strata_list <- master_strata_list[sol_idx]
strata_stats_list <- master_strata_stats_list[sol_idx]
settings
source('~/GitHub/MS_OM_GoA/ForMadison/fit_models.R', echo=TRUE)
###############################################################################
## Project:       Cross-Validation Results
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   For each CV run, calculate relative root mean squre error of
##                density predictions
###############################################################################
rm(list = ls())
##################################################
####   Import Libraries
##################################################
library(VAST)
library(RANN)
library(tidyr)
##################################################
####   Set up directores
##################################################
which_machine <- c("Zack_MAC" = 1, "Zack_PC" = 2, "Zack_GI_PC" = 3)[3]
VAST_dir <-  "G:/Oyafuso/VAST_Runs_EFH/Single_Species/"
github_dir <- "C:/Users/zack.oyafuso/Work/GitHub/Optimal_Allocation_GoA/"
##################################
## Import Strata Allocations and spatial grid and predicted density
##################################
load(paste0(github_dir, "data/Extrapolation_depths.RData"))
which_spp <- c(
"Atheresthes stomias",
"Gadus chalcogrammus",
"Gadus macrocephalus",
"Glyptocephalus zachirus",
"Hippoglossoides elassodon",
"Hippoglossus stenolepis",
"Lepidopsetta bilineata",
"Lepidopsetta polyxystra",
"Microstomus pacificus",
"Sebastes alutus",
"Sebastes B_R",
"Sebastes brevispinis",
"Sebastes polyspinis",
"Sebastes variabilis",
"Sebastolobus alascanus",
"Anoplopoma fimbria",
"Beringraja spp.",
"Octopus spp.",
"Pleurogrammus monopterygius",
"Sebastes borealis",
# "Sebastes ruberrimus",
"Sebastes variegatus",
"Squalus suckleyi"
)
ns <- length(which_spp)
##################################################
####   Result Objects
##################################################
NFold <- 10
NTime <- 11
CV_df <- expand.grid(species = which_spp,
depth = c(T, F),
fold = 1:NFold,
stringsAsFactors = F)
CV_df[,c("max_grad", "pdHess", "bound_check", "pred_nll",
"RMSE", "RRMSE", "MAE", "RMAE")] <- NA
for (irow in (1:nrow(CV_df)) ) {
#Load fitted object
result_dir <- paste0(VAST_dir, CV_df$species[irow],
ifelse(CV_df$depth[irow],  "_depth", ""), "/")
filename <- paste0(result_dir, "CV_", CV_df$fold[irow], "/fit.RData")
if ( file.exists(filename) ){
load(filename)
#Final Gradient
CV_df$max_grad[irow] <-
max(abs(fit_new$parameter_estimates$diagnostics$final_gradient))
#Check whether hessian matrix is positive definite
CV_df$pdHess[irow] <- fit_new$parameter_estimates$SD$pdHess
#check_fit chekcs bounds, TRUE is bad and FALSE is good
CV_df$bound_check[irow] <- (check_fit(fit_new$parameter_estimates))
CV_df$pred_nll[irow] <- fit_new$Report$pred_jnll
#Extract incides of withheld data
withheld_idx <- which(fit_new$data_list$PredTF_i == T)
#Withheld data locations, species/year indices, observed CPUE
withheld_df <- data.frame(
idx =  withheld_idx,
E_km = fit_new$spatial_list$loc_i[withheld_idx,"E_km"],
N_km = fit_new$spatial_list$loc_i[withheld_idx,"N_km"],
year = 1+fit_new$data_list$t_i[withheld_idx],
obs_density = (fit_new$data_frame$b_i/fit_new$data_frame$a_i)[withheld_idx]
)
#Extrapolation Grid locations
loc_g <- fit_new$spatial_list$loc_g
#which extrapoaltion grid cells are closest to each withheld data location
grid_idx <- RANN::nn2(query = withheld_df[,c("E_km", "N_km")],
data = loc_g,
k = 1)$nn.idx
for (jrow in 1:nrow(withheld_df)) {
withheld_df$pred_density[jrow] <-
fit_new$Report$D_gct[grid_idx[jrow], , withheld_df$year[jrow]]
}
#Calculate mean absolute error and root mean square error
CV_df$MAE[irow] = mean(abs(withheld_df$obs_density -
withheld_df$pred_density))
CV_df$RMSE[irow] = sqrt(mean((withheld_df$obs_density -
withheld_df$pred_density)^2))
#Calculate mean predicted density for calculation of RRMSE and RMAE
mean_pred_density <- mean(withheld_df$obs_density)
CV_df$RRMSE[irow] <- CV_df$RMSE[irow] / mean_pred_density
CV_df$RMAE[irow] <- CV_df$MAE[irow] / mean_pred_density
print(paste0("Done with: ", CV_df$species[irow], ", ",
ifelse(CV_df$depth[irow], "Depth, ", "No Depth, "),
"Fold Number ", CV_df$fold[irow]))
}
}
for (irow in (298:nrow(CV_df))[-297] ) {
#Load fitted object
result_dir <- paste0(VAST_dir, CV_df$species[irow],
ifelse(CV_df$depth[irow],  "_depth", ""), "/")
filename <- paste0(result_dir, "CV_", CV_df$fold[irow], "/fit.RData")
if ( file.exists(filename) ){
load(filename)
#Final Gradient
CV_df$max_grad[irow] <-
max(abs(fit_new$parameter_estimates$diagnostics$final_gradient))
#Check whether hessian matrix is positive definite
CV_df$pdHess[irow] <- fit_new$parameter_estimates$SD$pdHess
#check_fit chekcs bounds, TRUE is bad and FALSE is good
CV_df$bound_check[irow] <- (check_fit(fit_new$parameter_estimates))
CV_df$pred_nll[irow] <- fit_new$Report$pred_jnll
#Extract incides of withheld data
withheld_idx <- which(fit_new$data_list$PredTF_i == T)
#Withheld data locations, species/year indices, observed CPUE
withheld_df <- data.frame(
idx =  withheld_idx,
E_km = fit_new$spatial_list$loc_i[withheld_idx,"E_km"],
N_km = fit_new$spatial_list$loc_i[withheld_idx,"N_km"],
year = 1+fit_new$data_list$t_i[withheld_idx],
obs_density = (fit_new$data_frame$b_i/fit_new$data_frame$a_i)[withheld_idx]
)
#Extrapolation Grid locations
loc_g <- fit_new$spatial_list$loc_g
#which extrapoaltion grid cells are closest to each withheld data location
grid_idx <- RANN::nn2(query = withheld_df[,c("E_km", "N_km")],
data = loc_g,
k = 1)$nn.idx
for (jrow in 1:nrow(withheld_df)) {
withheld_df$pred_density[jrow] <-
fit_new$Report$D_gct[grid_idx[jrow], , withheld_df$year[jrow]]
}
#Calculate mean absolute error and root mean square error
CV_df$MAE[irow] = mean(abs(withheld_df$obs_density -
withheld_df$pred_density))
CV_df$RMSE[irow] = sqrt(mean((withheld_df$obs_density -
withheld_df$pred_density)^2))
#Calculate mean predicted density for calculation of RRMSE and RMAE
mean_pred_density <- mean(withheld_df$obs_density)
CV_df$RRMSE[irow] <- CV_df$RMSE[irow] / mean_pred_density
CV_df$RMAE[irow] <- CV_df$MAE[irow] / mean_pred_density
print(paste0("Done with: ", CV_df$species[irow], ", ",
ifelse(CV_df$depth[irow], "Depth, ", "No Depth, "),
"Fold Number ", CV_df$fold[irow]))
}
}
##################################################
####  Calculate summed predicted NLL across folds and Mean RRMSE across folds
##################################################
tidyr::spread(data = aggregate(pred_nll ~ species + depth,
data = CV_df,
FUN = sum),
key = "depth",
value = "pred_nll")
RMSE <- tidyr::spread(data = aggregate(RMSE ~ species + depth,
data = CV_df,
FUN = mean),
key = "depth",
value = "RMSE")
RMSE$depth_in_model <- c(F, T)[apply(X = RMSE[,-1],
MARGIN = 1,
FUN = which.min)]
##################################################
####   Create the result object that would go into the optimizations
##################################################
N <- nrow(Extrapolation_depths)
D_gct = Index <- array(dim = c(N, ns, 24),
dimnames = list(NULL, sort(which_spp), NULL))
for(ispp in 1:ns){
depth_in_model <- RMSE$depth_in_model[ispp]
result_dir = paste0(VAST_dir, RMSE$species[ispp],
ifelse(depth_in_model, "_depth", ""),
"/")
load(paste0(result_dir, "/fit.RData"))
D_gct[,ispp,] = fit$Report$D_gct[,1,]
Index[,ispp,] = fit$Report$Index_gctl[,1, ,1]
print(result_dir)
}
##################################################
####   Save
##################################################
save("RMSE", file = paste0(github_dir, "/data/RMSE_VAST_models.RData"))
save("D_gct", file = paste0(github_dir, "/data/fit_density.RData") )
save("Index", file = paste0(github_dir, "/data/fit_index.RData") )
load("~/GitHub/Optimal_Allocation_GoA/data/optimization_data.RData")
sci_names_all
###############################################################################
## Project:       Spatiotemporal Survey Optimization
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Conduct SamplingStrata R package multispecies stratified
##                survey optimization
###############################################################################
rm(list = ls())
##################################################
####  Install a forked version of the SamplingStrata Package from
####  zoyafuso-NOAA's Github page
####
####  Import other required packages
##################################################
library(devtools)
devtools::install_github(repo = "zoyafuso-NOAA/SamplingStrata")
library(SamplingStrata)
library(sp)
library(RColorBrewer)
library(raster)
##################################################
####   Set up directories based on whether the optimization is being conducted
####        on a multi-species or single-species level
##################################################
which_machine <- c("Zack_MAC" = 1, "Zack_PC" = 2, "Zack_GI_PC" = 3)[3]
github_dir <- paste0(c("/Users/zackoyafuso/Documents",
"C:/Users/Zack Oyafuso/Documents",
"C:/Users/zack.oyafuso/Work")[which_machine],
"/GitHub/Optimal_Allocation_GoA/")
##################################################
####   Load Data
####   Load Population CVs for use in the thresholds
##################################################
load(paste0(github_dir, "/data/optimization_data.RData"))
load(paste0(github_dir, "/data/Extrapolation_depths.RData"))
##################################################
####   Constants to specify before doing optimization
##################################################
which_domain <- c("full_domain", "district")[1]
sci_names_all[21]
run  = 6
##################################################
####   Constants to set up based on which_domain and which_species
##################################################
district_vals <- switch(which_domain,
"full_domain" = rep(1, n_cells),
"district" = district_vals)
n_dom <- length(unique(district_vals))
frame <- switch( which_domain,
"full_domain" = frame_all,
"district" = frame_district)[, c("domainvalue", "id",
"X1", "X2", "WEIGHT",
paste0("Y", which_species),
paste0("Y", which_species,
"_SQ_SUM"))]
names(frame)[6:7] <- paste0("Y", c("1", "1_SQ_SUM") )
no_strata <- switch(which_domain,
"full_domain" = 10,
"district" = rep(5, n_dom))
result_dir = paste0(github_dir,
"results/", which_domain, "/Single_Species_Optimization/",
gsub(x = sci_names_all[which_species],
pattern = ' ',
replacement = '_'), '/')
if(!dir.exists(result_dir)) dir.create(path = result_dir, recursive = T)
##################################################
####   Run optimization
##################################################
which_species = 21
##################################################
####   Constants to set up based on which_domain and which_species
##################################################
district_vals <- switch(which_domain,
"full_domain" = rep(1, n_cells),
"district" = district_vals)
n_dom <- length(unique(district_vals))
frame <- switch( which_domain,
"full_domain" = frame_all,
"district" = frame_district)[, c("domainvalue", "id",
"X1", "X2", "WEIGHT",
paste0("Y", which_species),
paste0("Y", which_species,
"_SQ_SUM"))]
names(frame)[6:7] <- paste0("Y", c("1", "1_SQ_SUM") )
no_strata <- switch(which_domain,
"full_domain" = 10,
"district" = rep(5, n_dom))
result_dir = paste0(github_dir,
"results/", which_domain, "/Single_Species_Optimization/",
gsub(x = sci_names_all[which_species],
pattern = ' ',
replacement = '_'), '/')
if(!dir.exists(result_dir)) dir.create(path = result_dir, recursive = T)
##################################################
####   Run optimization
##################################################
run
load("~/GitHub/Optimal_Allocation_GoA/results/full_domain/Single_Species_Optimization/Sebastolobus_alascanus/Run6/result_list.RData")
current_n = result_list$CV_constraints
current_n = result_list$n
CV_constraints <- result_list$CV_constraints
## Set up next run by changing slightly reducing the CV constraints
## CVs are reduced proportionally, based on the effort level
run <- run + 1
effort_level <- as.integer(cut(x = current_n,
breaks = c(0, 200, samples, 1000),
labels = 1:5))
effort_level
current_n
CV_constraints <- CV_constraints * c(0.80, 0.90, 0.95, 0.975)[effort_level]
#Create CV dataframe in the format of SamplingStrata
cv <- list()
cv[["CV1"]] <- as.numeric(CV_constraints)
cv[["DOM"]] <- 1:n_dom
cv[["domainvalue"]] <- 1:n_dom
cv <- as.data.frame(cv)
while (current_n <= 820 ) {
#Set wd for output files, create a directory if it doesn"t exist yet
temp_dir = paste0(result_dir, "Run", run)
if(!dir.exists(temp_dir)) dir.create(temp_dir, recursive = T)
setwd(temp_dir)
#Run optimization
par(mfrow = c(6,6),
mar = c(2,2,0,0))
solution <- optimStrata(method = "continuous",
errors = cv,
framesamp = frame,
iter = 300,
pops = 50,
elitism_rate = 0.1,
mut_chance = 1 / (no_strata[1] + 1),
nStrata = no_strata,
showPlot = T,
writeFiles = T)
sum_stats <- summaryStrata(solution$framenew,
solution$aggr_strata,
progress=FALSE)
plot_solution <- as.factor(paste(solution$framenew$DOMAINVALUE,
solution$framenew$STRATO))
plot_solution <- as.integer(plot_solution)
##Save a plot of the solution
goa <- sp::SpatialPointsDataFrame(
coords = Extrapolation_depths[, c("Lon", "Lat")],
data = data.frame(Str_no = plot_solution) )
goa_ras <- raster::raster(x = goa,
resolution = 0.075)
goa_ras <- raster::rasterize(x = goa,
y = goa_ras,
field = "Str_no")
png(filename = "solution.png",
width = 5,
height = 5,
units = "in",
res = 500)
par(mfrow = c(1, 1),
mar = c(1, 1, 1, 1))
plot(goa_ras,
axes = F,
asp = 1,
col = colorRampPalette(
brewer.pal(n = 11,
name = "Paired"))(length(unique(plot_solution)) ) )
rect(xleft = districts$W_lon,
xright = districts$E_lon,
ybottom = tapply(X = Extrapolation_depths$Lat,
INDEX = district_vals,
FUN = min),
ytop = tapply(X = Extrapolation_depths$Lat,
INDEX = district_vals,
FUN = max))
text(x = rowMeans(districts[, c("W_lon", "E_lon")]),
y = tapply(X = Extrapolation_depths$Lat,
INDEX = district_vals,
FUN = max),
labels = districts$district,
pos = 3)
box()
dev.off()
## Save Output
CV_constraints <- expected_CV(strata = solution$aggr_strata)
current_n <- sum(sum_stats$Allocation)
result_list <- list(solution = solution,
sum_stats = sum_stats,
CV_constraints = CV_constraints,
n = current_n)
save(list = "result_list", file = "result_list.RData")
## Set up next run by changing slightly reducing the CV constraints
## CVs are reduced proportionally, based on the effort level
run <- run + 1
effort_level <- as.integer(cut(x = current_n,
breaks = c(0, 200, samples, 1000),
labels = 1:5))
CV_constraints <- CV_constraints * c(0.80, 0.90, 0.95, 0.975)[effort_level]
#Create CV dataframe in the format of SamplingStrata
cv <- list()
cv[["CV1"]] <- as.numeric(CV_constraints)
cv[["DOM"]] <- 1:n_dom
cv[["domainvalue"]] <- 1:n_dom
cv <- as.data.frame(cv)
}
