yt = yrange[1] + yrange_diff * -0.25,
legend = pretty(((-ceiling(zlim_)):(ceiling(zlim_))), n = 3),
colorRampPalette(colors)(1000) ,
gradient = "x",
align = "rb",
cex = 0.75)
}
########################################
## Predicted Density
########################################
## Base Layer
plot(1,
type = "n",
xlim = range(Extrapolation_depths$E_km),
ylim = with(Extrapolation_depths,
c(min(N_km) + 0.0 * yrange_diff,
max(N_km) + 6 * yrange_diff)),
axes = F,
ann = F,
asp = 1)
box()
## Subtitle
mtext(side = 3,
text = "D) Predicted Density\n(kg/km2)",
line = -2.5,
cex = 0.8)
## Calculate quantiles of the density distribution
vals  = report$D_gct[, 1, years_included]
val_cuts = c(0,quantile(x = vals[vals > 10],
probs = seq(0, 1, length = 9) ))
#Add legend
val_cuts_legend = round(val_cuts[-1])
colors = c("lightgrey", brewer.pal(n = 7, name = "Oranges"), "black")
legend(x = xrange[1],
y = yrange[1] - yrange_diff * 0.15,
fill = colors,
bty = "n",
ncol = 3,
cex = 0.7,
legend = c("< 10", paste0("10-", val_cuts_legend[2]),
paste0(val_cuts_legend[2:(length(val_cuts_legend)-1)], "-",
val_cuts_legend[3:length(val_cuts_legend)])) )
## Loop over years and plot spatial distributions
for (iyear in 1:length(years_included)) {
#Extract density values for a species in a year,
vals  = report$D_gct[, 1, years_included[iyear]]
#plot density
goa = sp::SpatialPointsDataFrame(
coords = Extrapolation_depths[, c("E_km", "N_km")],
data = data.frame(density = vals) )
goa_ras = raster::raster(x = goa,
resolution = 10)
goa_ras = raster::rasterize(x = goa,
y = goa_ras,
field = "density")
#Discretize into quantiles
values(goa_ras) = cut(x = values(goa_ras),
breaks = val_cuts)
offset_y <- 0.6 * yrange_diff * (iyear - 1)
goa_ras <- raster::shift(goa_ras,
dy = offset_y )
#lay image
image(x = goa_ras,
asp = 1,
axes = F,
ann = F,
add = T,
col = colors)
#Year label
text(x = goa_ras@extent[1] + 0.7 * diff(goa_ras@extent[1:2]),
y = goa_ras@extent[3]+ 0.7 * diff(goa_ras@extent[3:4]),
labels = year_set[years_included[iyear]],
cex = 1)
}
## Calculate DHARMa Residuals
dyn.load(paste0(result_dir, "/VAST_v12_0_0.dll"))
dharmaRes = summary( fit, what = "residuals", working_dir = NA )
dyn.unload(paste0(result_dir, "/VAST_v12_0_0.dll"))
par(mar = c(3.5, 4, 1.25, 1))
###################################
## QQ Plot
###################################
gap::qqunif(dharmaRes$scaledResiduals, pch = 2, bty = "n",
logscale = F, col = "black", cex = 0.6,
cex.main = 1, ann = F, cex.axis = 0.8)
mtext(side = 1, line = 2, text = "Expected", cex = 0.7)
mtext(side = 2, line = 2.5, text = "Observed", cex = 0.7)
box()
box(which = "figure")
text(x = -0.31,
y = 1.05,
label = "E)",
xpd = NA,
cex = 1.25)
###################################
## Residual Plot
###################################
DHARMa::plotResiduals(dharmaRes,
rank = TRUE,
ann = F,
xlim = c(0, 1))
mtext(side = 1,
line = 2,
text = "Rank-Transformed Model Predictions",
cex = 0.6)
mtext(side = 2,
line = 2,
text = "Standardized\nResidual",
cex = 0.6)
box(which = "figure")
text(x = -0.3,
y = 1.05,
label = "F)",
xpd = NA,
cex = 1.25)
#############################
## Residuals in Space
#############################
goa = sp::SpatialPointsDataFrame(
coords = fit$spatial_list$loc_i,
data = data.frame(PIT = dharmaRes$scaledResiduals) )
goa_ras = raster::raster(x = goa,
resolution = 15)
goa_ras = raster::rasterize(x = goa,
y = goa_ras,
field = "PIT")
par(mar = c(1, 1, 1, 1))
image(goa_ras,
col = RColorBrewer::brewer.pal(n = 11, name = "RdBu"),
zlim = c(0, 1),
axes = F,
ann = F,
asp = 1)
box(which = "figure")
## Legend
plotrix::color.legend(
xl = xrange[1] + xrange_diff *  0.25,
xr = xrange[1] + xrange_diff *  0.75,
yb = yrange[1] + yrange_diff * -0.30,
yt = yrange[1] + yrange_diff * -0.15,
legend = seq(from = 0, to = 1, by = 0.25),
rect.col = RColorBrewer::brewer.pal(n = 11, name = "RdBu"),
gradient = "x",
align = "rb",
cex = 0.5)
text(x = xrange[1] + xrange_diff * 0,
y = yrange[2] + yrange_diff * 0.35,
labels = "G)",
xpd = NA,
cex = 1.25)
dev.off()
}
## Project:       Data synthesis for stratified survey optimization
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Create dataset used for all optimization runs based on a
##                Gulf of Alaska groundfish VAST spatiotemporal
##                operating single-species models
##
##                Calculate true mean density across years for each species
##
##                Set up other constants used in downstream processes
###############################################################################
rm(list = ls())
##################################################
####    Set up directories here first
##################################################
which_machine <- c("Zack_MAC" = 1, "Zack_PC" = 2, "Zack_GI_PC" = 3)[3]
github_dir <- paste0(c("/Users/zackoyafuso/Documents",
"C:/Users/Zack Oyafuso/Documents",
"C:/Users/zack.oyafuso/Work")[which_machine],
"/GitHub/Optimal_Allocation_GoA/")
##################################################
####   Load the true density, true index, and spatial domain dataset
##################################################
load(paste0(github_dir,  "data/fit_density.RData"))
load(paste0(github_dir,  "data/fit_Index.RData"))
load(paste0(github_dir, "/data/Extrapolation_depths.RData"))
load(paste0(github_dir,  "data/fit_index.RData"))
## Project:       Data synthesis for stratified survey optimization
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Create dataset used for all optimization runs based on a
##                Gulf of Alaska groundfish VAST spatiotemporal
##                operating single-species models
##
##                Calculate true mean density across years for each species
##
##                Set up other constants used in downstream processes
###############################################################################
rm(list = ls())
##################################################
####    Set up directories here first
##################################################
which_machine <- c("Zack_MAC" = 1, "Zack_PC" = 2, "Zack_GI_PC" = 3)[3]
github_dir <- paste0(c("/Users/zackoyafuso/Documents",
"C:/Users/Zack Oyafuso/Documents",
"C:/Users/zack.oyafuso/Work")[which_machine],
"/GitHub/Optimal_Allocation_GoA/")
##################################################
####   Load the true density, true index, and spatial domain dataset
##################################################
load(paste0(github_dir,  "data/fit_density.RData"))
load(paste0(github_dir,  "data/fit_index.RData"))
load(paste0(github_dir, "/data/Extrapolation_depths.RData"))
## Years to use
year_set <- 1996:2019
years_included <- c(1, 4, 8, 10, 12, 14, 16, 18, 20, 22, 24)
n_years <- length(years_included)
## Number of sampling grids
n_cells <- nrow(Extrapolation_depths)
## Scientific and common names used in optimization
sci_names_opt <- c("Atheresthes stomias", "Gadus chalcogrammus",
"Gadus macrocephalus", "Glyptocephalus zachirus",
"Hippoglossoides elassodon", "Hippoglossus stenolepis",
"Lepidopsetta bilineata", "Lepidopsetta polyxystra",
"Microstomus pacificus", "Sebastes alutus", "Sebastes B_R",
"Sebastes brevispinis", "Sebastes polyspinis",
"Sebastes variabilis", "Sebastolobus alascanus" )
common_names_opt <- c("arrowtooth flounder", "Alaska pollock", "Pacific cod",
"rex sole", "flathead sole", "Pacific halibut",
"southern rock sole", "northern rock sole",
"Pacific Dover sole", "Pacific ocean perch",
"blackspotted/rougheye\nrockfishes",
"silvergrey rockfish", "northern rockfish",
"dusky rockfish", "shortspine thornyhead")
ns_opt <- length(sci_names_opt)
sci_names_eval <- c("Anoplopoma fimbria", "Beringraja spp", "Octopus spp",
"Pleurogrammus monopterygius", "Sebastes borealis",
# "Sebastes ruberrimus",
"Sebastes variegatus", "Squalus suckleyi")
common_names_eval <- c("sablefish", "skates spp.", "Octopus spp.",
"Atka mackerel", "shortraker rockfish",
# "yelloweye rockfish",
"harlequin rockfish", "spiny dogfish")
ns_eval <- length(sci_names_eval)
## In case we need it, all species names together
sci_names_all <- sort(c(sci_names_opt, sci_names_eval))
common_names_all <- c(common_names_opt,
common_names_eval)[order(c(sci_names_opt,
sci_names_eval))]
ns_all <- ns_opt + ns_eval
spp_idx_opt <- which(sci_names_all %in% sci_names_opt)
spp_idx_eval <- which(sci_names_all %in% sci_names_eval)
## Sample sizes across 1, 2, and 3 boats
samples <- c(280, 550, 820)
n_boats <- length(samples)
## Number of strata to input into optimization
stratas <- c(10, 15, 20)
n_strata <- length(stratas)
## Specify Management Districts
districts <- data.frame("reg_area" = c("WRA", "CRA",
"CRA", "ERA", "ERA"),
"district" = c("W", "Chirikof",
"Kodiak", "Yakutat", "SE"),
"domainvalue" = 1:5,
"W_lon" = c(-170, -159, -154, -147, -140),
"E_lon" = c(-159, -154, -147, -140, -132))
n_dom <- nrow(districts)
district_vals <- cut(x = Extrapolation_depths$Lon,
breaks = c(-170, -159, -154, -147, -140, -132),
labels = 1:5)
districts[, c("W_UTM", "E_UTM")] <-
do.call(rbind,tapply(X = Extrapolation_depths$E_km,
INDEX = district_vals,
FUN = range) )
## Number of times to simulate survey
n_iters <- 500
obs_cv <- c(0, 0.25, 0.5, 1) #low to high sampling CVs
n_obs_cv <- length(obs_cv)
####           values so that the lowest value is 0
####   X2: strata variable 2: depth of cell (m)
####
####   Variables used to more efficiently calcualte stratum variance
####
####   WEIGHT: number of observed years
####   Y1, Y2, ... : density for a given cell summed across observed years
####   Y1_SQ_SUM, Y2_SQ_SUM, ... : density-squared for a given cell,
####           summed across observed years
##################################################
frame_all <- cbind(
data.frame(domainvalue = 1,
id = 1:n_cells,
X1 = with(Extrapolation_depths, E_km - min(E_km)),
X2 = Extrapolation_depths$DEPTH_EFH,
WEIGHT = n_years),
matrix(data = apply(X = D_gct[, , years_included],
MARGIN = c(1, 2),
FUN = sum),
ncol = ns_all,
dimnames = list(NULL, paste0("Y", 1:ns_all))),
matrix(data = apply(X = D_gct[, , years_included],
MARGIN = c(1, 2),
FUN = function(x) sum(x^2)),
ncol = ns_all,
dimnames = list(NULL, paste0("Y", 1:ns_all, "_SQ_SUM")))
)
frame_district <- cbind(data.frame(
domainvalue = cut(x = Extrapolation_depths$Lon,
breaks = c(-170, -159, -154, -147, -140, -132),
labels = 1:5),
id = 1:n_cells,
X1 = with(Extrapolation_depths, E_km - min(E_km)),
X2 = Extrapolation_depths$DEPTH_EFH,
WEIGHT = n_years),
matrix(data = apply(X = D_gct[, , years_included],
MARGIN = c(1, 2),
FUN = sum),
ncol = ns_all,
dimnames = list(NULL, paste0("Y", 1:ns_all))),
matrix(data = apply(X = D_gct[, , years_included],
MARGIN = c(1, 2),
FUN = function(x) sum(x^2)),
ncol = ns_all,
dimnames = list(NULL, paste0("Y", 1:ns_all, "_SQ_SUM")))
)
##################################################
####   Calculate true mean density and true abundance index along with
####   the true abundance index within districts
##################################################
true_mean <- apply(X = D_gct[, , years_included],
MARGIN = 2:3,
FUN = mean)
true_index <- apply(X = Index[, , years_included],
MARGIN = 2:3,
FUN = sum)
true_index_district <- apply(X = Index[,, years_included],
MARGIN = 2:3,
FUN = function(x) tapply(x,
INDEX = district_vals,
FUN = sum))
true_index_district <- aperm(a = true_index_district,
perm = c(2,3,1))
##################################################
####   Save Data
##################################################
save(list = c("frame_all", "frame_district",
"districts", "district_vals", "n_dom",
"true_mean", "true_index", "true_index_district",
"ns_all", "ns_eval", "ns_opt",
"common_names_all", "common_names_eval", "common_names_opt",
"sci_names_all", "sci_names_eval", "sci_names_opt",
"spp_idx_eval", "spp_idx_opt",
"year_set", "years_included", "n_years",
"n_cells", "samples", "n_boats", "n_iters",
"obs_cv", "n_obs_cv",
"stratas", "n_strata"),
file = paste0(github_dir, "data/optimization_data.RData"))
source('~/GitHub/Optimal_Allocation_GoA/analysis_scripts/optimization_data.R', echo=TRUE)
###############################################################################
## Project:       Spatiotemporal Survey Optimization
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Conduct SamplingStrata R package multispecies stratified
##                survey optimization
###############################################################################
rm(list = ls())
##################################################
####  Install a forked version of the SamplingStrata Package from
####  zoyafuso-NOAA's Github page
####
####  Import other required packages
##################################################
library(devtools)
devtools::install_github(repo = "zoyafuso-NOAA/SamplingStrata")
library(SamplingStrata)
library(sp)
library(RColorBrewer)
library(raster)
##################################################
####   Set up directories based on whether the optimization is being conducted
####        on a multi-species or single-species level
##################################################
which_machine <- c("Zack_MAC" = 1, "Zack_PC" = 2, "Zack_GI_PC" = 3)[3]
github_dir <- paste0(c("/Users/zackoyafuso/Documents",
"C:/Users/Zack Oyafuso/Documents",
"C:/Users/zack.oyafuso/Work")[which_machine],
"/GitHub/Optimal_Allocation_GoA/")
##################################################
####   Load Data
####   Load Population CVs for use in the thresholds
##################################################
load(paste0(github_dir, "/data/optimization_data.RData"))
load(paste0(github_dir, "/data/Extrapolation_depths.RData"))
which_species
##################################################
####   Constants to specify before doing optimization
##################################################
which_domain <- c("full_domain", "district")[1]
for (which_species in 1) {
##################################################
####   Constants to set up based on which_domain and which_species
##################################################
frame <- switch( which_domain,
"full_domain" = frame_all,
"district" = frame_district)[, c("domainvalue", "id",
"X1", "X2", "WEIGHT",
paste0("Y", which_species),
paste0("Y", which_species,
"_SQ_SUM"))]
names(frame)[6:7] <- paste0("Y", c("1", "1_SQ_SUM") )
n_dom <- length(unique(frame$domainvalue))
no_strata <- switch(which_domain,
"full_domain" = 10,
"district" = rep(5, n_dom))
result_dir = paste0(github_dir,
"results/", which_domain,
"/Single_Species_Optimization/",
gsub(x = sci_names_all[which_species],
pattern = ' ',
replacement = '_'), '/')
if(!dir.exists(result_dir)) dir.create(path = result_dir, recursive = T)
##################################################
####   Run optimization
##################################################
##Initial Conditions
run <- 1
current_n <- 0
## Initiate CVs to be those calculated under SRS
srs_stats <- SamplingStrata::buildStrataDF(
dataset = cbind( subset(frame, select = -c(X1, X2)),
X1 = 1))
srs_n <- as.numeric(280 * table(frame$domainvalue) / n_cells)
srs_var <- srs_stats$S1^2 * (1 - srs_n / n_cells) / srs_n
srs_cv <- sqrt(srs_var) / srs_stats$M1
cv <- list()
cv[["CV1"]] <- srs_cv
cv[["DOM"]] <- 1:n_dom
cv[["domainvalue"]] <- 1:n_dom
cv <- as.data.frame(cv)
while (current_n <= 820 ) {
#Set wd for output files, create a directory if it doesn"t exist yet
temp_dir = paste0(result_dir, "Run", run)
if(!dir.exists(temp_dir)) dir.create(temp_dir, recursive = T)
setwd(temp_dir)
#Run optimization
par(mfrow = c(6,6),
mar = c(2,2,0,0))
solution <- optimStrata(method = "continuous",
errors = cv,
framesamp = frame,
iter = 300,
pops = 50,
elitism_rate = 0.1,
mut_chance = 1 / (no_strata[1] + 1),
nStrata = no_strata,
showPlot = T,
writeFiles = T)
sum_stats <- summaryStrata(solution$framenew,
solution$aggr_strata,
progress=FALSE)
plot_solution <- as.factor(paste(solution$framenew$DOMAINVALUE,
solution$framenew$STRATO))
plot_solution <- as.integer(plot_solution)
##Save a plot of the solution
goa <- sp::SpatialPointsDataFrame(
coords = Extrapolation_depths[, c("Lon", "Lat")],
data = data.frame(Str_no = plot_solution) )
goa_ras <- raster::raster(x = goa,
resolution = 0.075)
goa_ras <- raster::rasterize(x = goa,
y = goa_ras,
field = "Str_no")
png(filename = "solution.png",
width = 5,
height = 5,
units = "in",
res = 500)
par(mfrow = c(1, 1),
mar = c(1, 1, 1, 1))
plot(goa_ras,
axes = F,
asp = 1,
col = colorRampPalette(
brewer.pal(n = 11,
name = "Paired"))(length(unique(plot_solution)) ) )
rect(xleft = districts$W_lon,
xright = districts$E_lon,
ybottom = tapply(X = Extrapolation_depths$Lat,
INDEX = district_vals,
FUN = min),
ytop = tapply(X = Extrapolation_depths$Lat,
INDEX = district_vals,
FUN = max))
text(x = rowMeans(districts[, c("W_lon", "E_lon")]),
y = tapply(X = Extrapolation_depths$Lat,
INDEX = district_vals,
FUN = max),
labels = districts$district,
pos = 3)
box()
dev.off()
## Save Output
CV_constraints <- expected_CV(strata = solution$aggr_strata)
current_n <- sum(sum_stats$Allocation)
result_list <- list(solution = solution,
sum_stats = sum_stats,
CV_constraints = CV_constraints,
n = current_n)
save(list = "result_list", file = "result_list.RData")
## Set up next run by changing slightly reducing the CV constraints
## CVs are reduced proportionally, based on the effort level
run <- run + 1
effort_level <- as.integer(cut(x = current_n,
breaks = c(0, 200, samples, 1000),
labels = 1:5))
CV_constraints <- CV_constraints * c(0.80, 0.90, 0.95, 0.975)[effort_level]
#Create CV dataframe in the format of SamplingStrata
cv <- list()
cv[["CV1"]] <- as.numeric(CV_constraints)
cv[["DOM"]] <- 1:n_dom
cv[["domainvalue"]] <- 1:n_dom
cv <- as.data.frame(cv)
}
}
